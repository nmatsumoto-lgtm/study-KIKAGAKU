{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOLosFBsIzbSPriinCIzLdc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmatsumoto-lgtm/study-KIKAGAKU/blob/main/%E4%B8%8D%E5%8B%95%E7%94%A3%E4%BE%A1%E6%A0%BC%E4%BA%88%E6%B8%AC%E3%82%A2%E3%83%97%E3%83%AA_Ver_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecn2Ecyv-_Do"
      },
      "outputs": [],
      "source": [
        "!pip -q install lightgbm==4.5.0 optuna==3.6.1 joblib pandas numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import json\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from joblib import dump"
      ],
      "metadata": {
        "id": "lLSnSHj3_Z-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 0\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "eW4OJKbo_hIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IN = Path(\"data/interim/train_tabular.csv\")\n",
        "OUT_DIR = Path(\"models\"); OUT_DIR.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "O15JAXWq_lwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 1) データ読み込み & 追加特徴量\n",
        "# ============================\n",
        "\n",
        "def _oof_target_median(df: pd.DataFrame, key, y: np.ndarray, n_splits: int = 5) -> np.ndarray:\n",
        "    \"\"\"key は str でも list[str] でもOK。OOFで groupby(key) の中央値を割り当て。\"\"\"\n",
        "    if isinstance(key, str):\n",
        "        key_cols = [key]\n",
        "    else:\n",
        "        key_cols = list(key)\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    oof = np.zeros(len(df), dtype=float)\n",
        "    key_df = df[key_cols].copy()\n",
        "    for tr_idx, va_idx in kf.split(df):\n",
        "        g = pd.DataFrame({\"y\": y[tr_idx]})\n",
        "        for c in key_cols:\n",
        "            g[c] = key_df.iloc[tr_idx][c].values\n",
        "        med = g.groupby(key_cols)[\"y\"].median()\n",
        "        # map 用の結合キー（高速・簡易）\n",
        "        tr_key = key_df.iloc[va_idx].astype(str).agg(\"§\".join, axis=1)\n",
        "        med_key = med.reset_index()\n",
        "        med_key[\"__k__\"] = med_key[key_cols].astype(str).agg(\"§\".join, axis=1)\n",
        "        map_dict = pd.Series(med_key[\"y\"].values, index=med_key[\"__k__\"]).to_dict()\n",
        "        mapped = tr_key.map(map_dict)\n",
        "        oof[va_idx] = mapped.fillna(float(np.median(y[tr_idx]))).values\n",
        "    return oof\n",
        "\n",
        "def build_table_and_features() -> tuple[pd.DataFrame, list[str], list[str], list[str], list[int]]:\n",
        "    df = pd.read_csv(IN)\n",
        "\n",
        "    # ===== 目標（対数）=====\n",
        "    y = df[\"price_yen\"].astype(float).values\n",
        "    y_log = np.log1p(y)\n",
        "\n",
        "    # ===== 追加特徴量 =====\n",
        "    df[\"access_score\"] = 1.0 / (1.0 + df[\"walk_min\"].astype(float))\n",
        "    df[\"sqrt_area\"] = np.sqrt(np.clip(df[\"area_sqm\"].astype(float), 0, None))\n",
        "    df[\"log_area\"] = np.log1p(np.clip(df[\"area_sqm\"].astype(float), 0, None))\n",
        "    df[\"age_sqrt\"] = np.sqrt(np.clip(df[\"築年数\"].astype(float), 0, None))\n",
        "    df[\"area_x_access\"] = df[\"area_sqm\"].astype(float) * df[\"access_score\"].astype(float)\n",
        "\n",
        "    # 取引年（欠損は全体中央値で補完）\n",
        "    if \"txn_year\" in df.columns:\n",
        "        df[\"txn_year\"] = pd.to_numeric(df[\"txn_year\"], errors=\"coerce\")\n",
        "        df[\"txn_year\"] = df[\"txn_year\"].fillna(df[\"txn_year\"].median())\n",
        "    else:\n",
        "        # 取引年が無いデータでも動くように、現在年で埋める\n",
        "        df[\"txn_year\"] = datetime.now().year\n",
        "\n",
        "    # 年の離散化（木が扱いやすい整数カテゴリ）\n",
        "    df[\"txn_year_int\"] = df[\"txn_year\"].round().astype(int)\n",
        "\n",
        "    # 頻度特徴量\n",
        "    station_cnt = df[\"station\"].value_counts()\n",
        "    layout_cnt  = df[\"layout\"].value_counts()\n",
        "    df[\"station_count\"] = df[\"station\"].map(station_cnt).fillna(0).astype(int)\n",
        "    df[\"layout_count\"]  = df[\"layout\"].map(layout_cnt).fillna(0).astype(int)\n",
        "\n",
        "    # OOF 目標エンコード（駅/間取り/駅×年） ※対数ターゲットで作る\n",
        "    df[\"station_oof_median_log\"]      = _oof_target_median(df, \"station\", y_log)\n",
        "    df[\"layout_oof_median_log\"]       = _oof_target_median(df, \"layout\",  y_log)\n",
        "    df[\"station_year_oof_median_log\"] = _oof_target_median(df, [\"station\", \"txn_year_int\"], y_log)\n",
        "\n",
        "    # 推論時に使う学習時統計\n",
        "    station_med_map = pd.DataFrame({\"station\": df[\"station\"], \"y_log\": y_log}).groupby(\"station\")[\"y_log\"].median().to_dict()\n",
        "    layout_med_map  = pd.DataFrame({\"layout\":  df[\"layout\"],  \"y_log\": y_log}).groupby(\"layout\")[\"y_log\"].median().to_dict()\n",
        "    st_year_med_map = (pd.DataFrame({\"station\": df[\"station\"], \"year\": df[\"txn_year_int\"], \"y_log\": y_log})\n",
        "                       .groupby([\"station\",\"year\"])[\"y_log\"].median().to_dict())\n",
        "    global_station_med = float(np.median(list(station_med_map.values()))) if len(station_med_map) else float(np.median(y_log))\n",
        "    global_layout_med  = float(np.median(list(layout_med_map.values())))  if len(layout_med_map)  else float(np.median(y_log))\n",
        "\n",
        "    # カテゴリ列\n",
        "    feat_cat = [\"station\", \"layout\", \"txn_year_int\"]  # 年もカテゴリとして持たせる\n",
        "\n",
        "    # 数値列（順序固定）\n",
        "    feat_num_base = [\"walk_min\", \"築年数\", \"area_sqm\"]\n",
        "    feat_num_extra = [\n",
        "        \"access_score\", \"sqrt_area\", \"log_area\", \"age_sqrt\",\n",
        "        \"area_x_access\", \"station_count\", \"layout_count\",\n",
        "        \"station_oof_median_log\", \"layout_oof_median_log\",\n",
        "        \"station_year_oof_median_log\",\n",
        "    ]\n",
        "    feat_num_all = feat_num_base + feat_num_extra\n",
        "\n",
        "    # 単調性制約（[cat..., num...] の順）\n",
        "    n_cat = len(feat_cat)\n",
        "    # walk_min は負、築年数は負、area_sqm は正、それ以外 0\n",
        "    mono_num = [-1, -1, +1] + [0] * (len(feat_num_all) - 3)\n",
        "    monotone_constraints = [0] * n_cat + mono_num\n",
        "\n",
        "    # ====== エンコードして学習用テーブル ======\n",
        "    oe = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "    X_cat = oe.fit_transform(df[feat_cat].fillna(\"NA\")).astype(\"int32\")\n",
        "    X_num = df[feat_num_all].astype(float).values\n",
        "    X = np.hstack([X_cat, X_num])\n",
        "\n",
        "    cat_cols = [f\"cat__{c}\" for c in feat_cat]\n",
        "    num_cols = feat_num_all.copy()\n",
        "    X_df = pd.DataFrame(X, columns=cat_cols + num_cols)\n",
        "    categorical_feature = cat_cols\n",
        "\n",
        "    meta = {\n",
        "        \"feat_cat\": feat_cat,\n",
        "        \"feat_num\": num_cols,\n",
        "        \"categorical_feature\": categorical_feature,\n",
        "        \"monotone_constraints\": monotone_constraints,\n",
        "    }\n",
        "\n",
        "    infer_maps = {\n",
        "        \"station_count_map\": station_cnt.to_dict(),\n",
        "        \"layout_count_map\": layout_cnt.to_dict(),\n",
        "        \"station_median_log_map\": station_med_map,\n",
        "        \"layout_median_log_map\": layout_med_map,\n",
        "        \"station_year_median_log_map\": {f\"{k[0]}§{k[1]}\": float(v) for k, v in st_year_med_map.items()},\n",
        "        \"global_station_median_log\": global_station_med,\n",
        "        \"global_layout_median_log\": global_layout_med,\n",
        "        \"feat_cat\": feat_cat,\n",
        "        \"feat_num\": num_cols,\n",
        "    }\n",
        "    return X_df, y_log, categorical_feature, monotone_constraints, meta, oe, infer_maps\n"
      ],
      "metadata": {
        "id": "eJwZjsfFADw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 2) Optuna でハイパラ探索\n",
        "# ============================\n",
        "\n",
        "def tune_with_optuna(\n",
        "    X_df: pd.DataFrame,\n",
        "    y_log: np.ndarray,\n",
        "    categorical_feature: list[str],\n",
        "    monotone_constraints: list[int],\n",
        "    n_trials: int = 80,\n",
        ") -> tuple[dict, int, float]:\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        params = {\n",
        "            \"objective\": \"rmse\",\n",
        "            \"metric\": \"rmse\",\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.08, log=True),\n",
        "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 127),                 # ← 上限を抑制\n",
        "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 120),     # ← 下限を底上げ\n",
        "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 0.9),\n",
        "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.7, 1.0),\n",
        "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),               # ← 1以上を強制\n",
        "            \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 3.0),\n",
        "            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 1.0, log=True),\n",
        "            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 1.0, log=True),\n",
        "            \"verbosity\": -1,\n",
        "            \"seed\": SEED,\n",
        "            \"monotone_constraints\": monotone_constraints,\n",
        "        }\n",
        "        rmsles, best_iters = [], []\n",
        "        for tr_idx, va_idx in kf.split(X_df):\n",
        "            X_tr, X_va = X_df.iloc[tr_idx], X_df.iloc[va_idx]\n",
        "            y_tr, y_va = y_log[tr_idx], y_log[va_idx]\n",
        "            dtr = lgb.Dataset(X_tr, label=y_tr, categorical_feature=categorical_feature, free_raw_data=True)\n",
        "            dva = lgb.Dataset(X_va, label=y_va, categorical_feature=categorical_feature, free_raw_data=True)\n",
        "\n",
        "            model = lgb.train(\n",
        "                params,\n",
        "                dtr,\n",
        "                valid_sets=[dva],\n",
        "                num_boost_round=4000,\n",
        "                callbacks=[lgb.early_stopping(300, verbose=False)],  # ← 少し長めに\n",
        "            )\n",
        "            pred_log = model.predict(X_va, num_iteration=model.best_iteration)\n",
        "            rmsle = float(np.sqrt(mean_squared_log_error(np.expm1(y_va), np.expm1(pred_log))))\n",
        "            rmsles.append(rmsle)\n",
        "            best_iters.append(model.best_iteration)\n",
        "        trial.set_user_attr(\"best_iters\", best_iters)\n",
        "        return float(np.mean(rmsles))\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    best_iters_list = study.best_trial.user_attrs.get(\"best_iters\", [1000])\n",
        "    best_round = int(np.clip(np.mean(best_iters_list), 100, 4000))\n",
        "    best_score = study.best_value\n",
        "    return best_params, best_round, best_score"
      ],
      "metadata": {
        "id": "Pb67dPghADsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 3) 最終学習（ポイント & 分位点）\n",
        "# ============================\n",
        "\n",
        "def train_final_models(\n",
        "    X_df: pd.DataFrame,\n",
        "    y_log: np.ndarray,\n",
        "    categorical_feature: list[str],\n",
        "    monotone_constraints: list[int],\n",
        "    best_params: dict,\n",
        "    best_round: int,\n",
        "):\n",
        "    base_params = dict(best_params)\n",
        "    base_params.update({\n",
        "        \"objective\": \"rmse\",\n",
        "        \"metric\": \"rmse\",\n",
        "        \"verbosity\": -1,\n",
        "        \"seed\": SEED,\n",
        "        # ★ ポイントモデルでは単調性制約を使う\n",
        "        \"monotone_constraints\": monotone_constraints,\n",
        "    })\n",
        "\n",
        "    # 生データを解放しない（categorical_feature を後で使えるように）\n",
        "    dtrain = lgb.Dataset(\n",
        "        X_df,\n",
        "        label=y_log,\n",
        "        categorical_feature=categorical_feature,\n",
        "        free_raw_data=False\n",
        "    )\n",
        "\n",
        "    # ---- ポイント（対数価格）----\n",
        "    model_point = lgb.train(base_params, dtrain, num_boost_round=best_round)\n",
        "\n",
        "    # ---- 分位点（q10/q90）----\n",
        "    models_q = {}\n",
        "    for alpha, tag in [(0.1, \"q10\"), (0.9, \"q90\")]:\n",
        "        q_params = dict(best_params)\n",
        "        q_params.update({\n",
        "            \"objective\": \"quantile\",\n",
        "            \"alpha\": alpha,\n",
        "            \"metric\": \"quantile\",\n",
        "            \"verbosity\": -1,\n",
        "            \"seed\": SEED,\n",
        "            # ★ ここが重要：quantile では単調性制約を外す\n",
        "            # \"monotone_constraints\": monotone_constraints,  # ←入れない\n",
        "        })\n",
        "        models_q[tag] = lgb.train(q_params, dtrain, num_boost_round=best_round)\n",
        "\n",
        "    return model_point, models_q\n"
      ],
      "metadata": {
        "id": "y2CDOFoaBSBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 入力CSV→中間CSVの自動生成（なければ作る） =====\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np, re\n",
        "from datetime import datetime\n",
        "\n",
        "RAW_CSV = Path(\"/content/Tokyo_Chuo Ward_20222_20251.csv\")\n",
        "IN = Path(\"data/interim/train_tabular.csv\")\n",
        "ST_OUT = Path(\"data/interim/stations.csv\")\n",
        "IN.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _read_chuo_and_save(raw_csv: Path, out_csv: Path, stations_csv: Path):\n",
        "    # エンコーディングを順に試す（Excel想定）\n",
        "    last_err = None\n",
        "    for enc in (\"cp932\", \"utf-8-sig\", \"utf-8\", \"utf-16\", \"utf-16le\", \"utf-16be\"):\n",
        "        try:\n",
        "            raw = pd.read_csv(raw_csv, encoding=enc)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            raw = None\n",
        "    if raw is None:\n",
        "        raise last_err\n",
        "\n",
        "    # ---- 年の抽出（和暦/西暦対応）----\n",
        "    def _to_year(x):\n",
        "        if pd.isna(x): return np.nan\n",
        "        s = str(x)\n",
        "        m = re.search(r\"(\\d{4})年\", s)\n",
        "        if m: return int(m.group(1))\n",
        "        era_base = {\"令和\":2018, \"平成\":1988, \"昭和\":1925}\n",
        "        for era, base in era_base.items():\n",
        "            m = re.search(fr\"{era}\\s*(\\d+)年\", s)\n",
        "            if m: return base + int(m.group(1))\n",
        "        return np.nan\n",
        "\n",
        "    # ---- 取引年（列が無ければ建物の保存年やファイル名からフォールバック）----\n",
        "    def _to_txn_year(s):\n",
        "        if pd.isna(s): return np.nan\n",
        "        ss = str(s)\n",
        "        # 例: \"2024年第2四半期\", \"2023年上半期\" などから西暦抽出\n",
        "        m = re.search(r\"(\\d{4})\", ss)\n",
        "        return float(m.group(1)) if m else np.nan\n",
        "\n",
        "    # 欲しい列が増えても落ちないように存在チェック\n",
        "    need_base = [\"最寄駅：名称\",\"最寄駅：距離（分）\",\"間取り\",\"面積（㎡）\",\"建築年\",\"取引価格（総額）\"]\n",
        "    miss = [c for c in need_base if c not in raw.columns]\n",
        "    if miss:\n",
        "        raise KeyError(f\"必要列が見つかりません: {miss}\")\n",
        "    df = raw[need_base].copy()\n",
        "\n",
        "    # 取引時期があれば読む\n",
        "    txn_year = None\n",
        "    if \"取引時期\" in raw.columns:\n",
        "        txn_year = raw[\"取引時期\"].apply(_to_txn_year)\n",
        "    # 全欠損なら建築年からの近似（現行の現在年は避ける）\n",
        "    if txn_year is None or txn_year.isna().all():\n",
        "        # ファイル名に西暦があれば拾う（例: Tokyo_Chuo Ward_20242_20251.csv → 2024〜2025）\n",
        "        mfile = re.findall(r\"(20\\d{2})\", raw_csv.name)\n",
        "        fallback_year = float(mfile[-1]) if mfile else np.nan\n",
        "        txn_year = pd.Series(fallback_year, index=df.index, dtype=\"float64\")\n",
        "\n",
        "    # ---- 築年数 = 取引年 − 建築年 ----\n",
        "    build_year = df[\"建築年\"].apply(_to_year)\n",
        "    df[\"txn_year\"] = txn_year.astype(float)\n",
        "    df[\"築年数\"] = (df[\"txn_year\"] - build_year).clip(lower=0)\n",
        "\n",
        "    # ---- 数値化ユーティリティ ----\n",
        "    def _to_num_series(s):\n",
        "        s = s.astype(str).str.replace(r\"[^\\d\\.]\", \"\", regex=True)\n",
        "        return pd.to_numeric(s, errors=\"coerce\")\n",
        "\n",
        "    # ---- 数値列の強制数値化 & 欠損補完 ----\n",
        "    for col in [\"最寄駅：距離（分）\",\"面積（㎡）\",\"築年数\"]:\n",
        "        s_num = _to_num_series(df[col])\n",
        "        med = s_num.median()\n",
        "        if pd.isna(med):\n",
        "            defaults = {\"最寄駅：距離（分）\":10.0, \"面積（㎡）\":40.0, \"築年数\":20.0}\n",
        "            med = defaults.get(col, 0.0)\n",
        "        df[col] = s_num.fillna(med)\n",
        "\n",
        "    # ---- 間取りの正規化 ----\n",
        "    def _normalize_layout(s):\n",
        "        if not isinstance(s,str): return \"その他\"\n",
        "        s = s.upper().replace(\"Ｌ\",\"L\").replace(\"Ｄ\",\"D\").replace(\"Ｋ\",\"K\").replace(\"Ｒ\",\"R\")\n",
        "        m = re.search(r\"(\\d+)(LDK|DK|K|R)\", s)\n",
        "        return m.group(0) if m else \"その他\"\n",
        "\n",
        "    # ---- 学習用テーブル ----\n",
        "    train = df.rename(columns={\n",
        "        \"最寄駅：名称\":\"station\",\n",
        "        \"最寄駅：距離（分）\":\"walk_min\",\n",
        "        \"面積（㎡）\":\"area_sqm\",\n",
        "        \"取引価格（総額）\":\"price_yen\",\n",
        "    })[[\"station\",\"walk_min\",\"築年数\",\"area_sqm\",\"price_yen\",\"txn_year\"]].copy()\n",
        "    train[\"layout\"] = raw[\"間取り\"].astype(str).apply(_normalize_layout)\n",
        "\n",
        "    # 不適切値の除去とクリップ\n",
        "    train[\"price_yen\"] = _to_num_series(train[\"price_yen\"]).fillna(0)\n",
        "    train = train[\n",
        "        (train[\"price_yen\"] > 0) &\n",
        "        (train[\"area_sqm\"]  > 0) &\n",
        "        (train[\"walk_min\"]  >= 0) &\n",
        "        (train[\"築年数\"]      >= 0)\n",
        "    ].copy()\n",
        "    train[\"area_sqm\"] = train[\"area_sqm\"].clip(8, 300)\n",
        "    train[\"walk_min\"] = train[\"walk_min\"].clip(0, 60)\n",
        "\n",
        "    # 保存\n",
        "    train.to_csv(out_csv, index=False)\n",
        "\n",
        "    # 駅リスト\n",
        "    s = (raw[\"最寄駅：名称\"].astype(str)\n",
        "           .replace({\"nan\":np.nan,\"None\":np.nan,\"\":np.nan})\n",
        "           .dropna()\n",
        "           .str.normalize(\"NFKC\")\n",
        "           .str.replace(\"（\",\"(\",regex=False).str.replace(\"）\",\")\",regex=False)\n",
        "           .str.replace(\"　\",\" \",regex=False).str.strip()\n",
        "           .str.replace(r\"\\s+\",\" \",regex=True))\n",
        "    pd.Series(sorted(s.unique())).to_csv(stations_csv, index=False, header=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "\n",
        "# まだ中間CSVがない場合は作る\n",
        "if not IN.exists():\n",
        "    if not RAW_CSV.exists():\n",
        "        raise FileNotFoundError(f\"Raw CSV が見つかりません: {RAW_CSV.resolve()}\")\n",
        "    _read_chuo_and_save(RAW_CSV, IN, ST_OUT)"
      ],
      "metadata": {
        "id": "djgwH5z8AQKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 4) 実行\n",
        "# ============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    assert IN.exists(), f\"Not found: {IN}\"\n",
        "\n",
        "    # ★ infer_maps まで受け取る（関数が infer_maps を返す実装になっている前提）\n",
        "    X_df, y_log, cat_cols, mono_cons, meta, oe, infer_maps = build_table_and_features()\n",
        "\n",
        "    print(f\"Train rows: {len(X_df):,}, cols: {X_df.shape[1]} (cats={len(cat_cols)})\")\n",
        "\n",
        "    best_params, best_round, best_score = tune_with_optuna(\n",
        "        X_df, y_log, cat_cols, mono_cons, n_trials=80\n",
        "    )\n",
        "    print(\"[OPTUNA] best RMSLE:\", round(best_score, 4))\n",
        "    print(\"[OPTUNA] best params:\")\n",
        "    for k, v in best_params.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print(\"[OPTUNA] best_round:\", best_round)\n",
        "\n",
        "    model_point, models_q = train_final_models(\n",
        "        X_df, y_log, cat_cols, mono_cons, best_params, best_round\n",
        "    )\n",
        "\n",
        "    # ===== 保存 =====\n",
        "    # 予測時に使うメタ情報（列順や制約）とエンコーダを一緒に保存しておく\n",
        "    dump({\n",
        "        \"model\": model_point,\n",
        "        \"encoder\": oe,\n",
        "        \"cat_cols\": meta[\"feat_cat\"],\n",
        "        \"num_cols\": meta[\"feat_num\"],\n",
        "        \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "        \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "        \"target\": \"log_price_yen\",\n",
        "    }, OUT_DIR / \"lgbm_optuna_point.pkl\")\n",
        "\n",
        "    dump({\n",
        "        \"model\": models_q[\"q10\"],\n",
        "        \"encoder\": oe,\n",
        "        \"cat_cols\": meta[\"feat_cat\"],\n",
        "        \"num_cols\": meta[\"feat_num\"],\n",
        "        \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "        \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "        \"target\": \"log_price_yen\",\n",
        "        \"alpha\": 0.1,\n",
        "    }, OUT_DIR / \"lgbm_optuna_q10.pkl\")\n",
        "\n",
        "    dump({\n",
        "        \"model\": models_q[\"q90\"],\n",
        "        \"encoder\": oe,\n",
        "        \"cat_cols\": meta[\"feat_cat\"],\n",
        "        \"num_cols\": meta[\"feat_num\"],\n",
        "        \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "        \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "        \"target\": \"log_price_yen\",\n",
        "        \"alpha\": 0.9,\n",
        "    }, OUT_DIR / \"lgbm_optuna_q90.pkl\")\n",
        "\n",
        "    with open(OUT_DIR / \"feature_config.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\n",
        "            \"feat_cat\": meta[\"feat_cat\"],\n",
        "            \"feat_num\": meta[\"feat_num\"],\n",
        "            \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "            \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "            \"notes\": \"y is log1p(price_yen). During inference, apply expm1 to predictions.\",\n",
        "        }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # ★ 推論用マップも保存（カッコを閉じるのを忘れない）\n",
        "    with open(OUT_DIR / \"infer_maps.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(infer_maps, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(\"Saved models →\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgDG4Y1nAbPv",
        "outputId": "73e4af54-45e0-46e2-9b7c-9dfc1092017d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-04 13:32:41,598] A new study created in memory with name: no-name-23a12e22-7307-483b-8549-2a334a516d27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 5,333, cols: 16 (cats=3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-04 13:32:42,309] Trial 0 finished with value: 0.208833667647713 and parameters: {'learning_rate': 0.01051212384762145, 'num_leaves': 67, 'min_data_in_leaf': 34, 'feature_fraction': 0.7465186911231043, 'bagging_fraction': 0.7759636930827386, 'bagging_freq': 8, 'min_gain_to_split': 2.9940882529901307, 'lambda_l1': 4.559494182949361e-06, 'lambda_l2': 1.4604132743874646e-08}. Best is trial 0 with value: 0.208833667647713.\n",
            "[I 2025-09-04 13:32:42,950] Trial 1 finished with value: 0.20567005252943066 and parameters: {'learning_rate': 0.04161378886114005, 'num_leaves': 61, 'min_data_in_leaf': 69, 'feature_fraction': 0.7213175651586841, 'bagging_fraction': 0.9373779572879641, 'bagging_freq': 1, 'min_gain_to_split': 2.7030469357311944, 'lambda_l1': 1.8339102816463442e-06, 'lambda_l2': 7.30934896233308e-08}. Best is trial 1 with value: 0.20567005252943066.\n",
            "[I 2025-09-04 13:32:43,586] Trial 2 finished with value: 0.20764929523073125 and parameters: {'learning_rate': 0.05053664916177309, 'num_leaves': 55, 'min_data_in_leaf': 80, 'feature_fraction': 0.7793874839867944, 'bagging_fraction': 0.7660431494311809, 'bagging_freq': 8, 'min_gain_to_split': 2.224583430431741, 'lambda_l1': 1.3447754913839988e-08, 'lambda_l2': 4.888359411707593e-07}. Best is trial 1 with value: 0.20567005252943066.\n",
            "[I 2025-09-04 13:32:45,532] Trial 3 finished with value: 0.20465891169134331 and parameters: {'learning_rate': 0.019751092868959225, 'num_leaves': 78, 'min_data_in_leaf': 55, 'feature_fraction': 0.8351275789223298, 'bagging_fraction': 0.9455713412106226, 'bagging_freq': 9, 'min_gain_to_split': 2.225935003173363, 'lambda_l1': 0.03208271137739596, 'lambda_l2': 0.00034477006653670203}. Best is trial 3 with value: 0.20465891169134331.\n",
            "[I 2025-09-04 13:32:46,387] Trial 4 finished with value: 0.20130416998244618 and parameters: {'learning_rate': 0.01583339725704236, 'num_leaves': 73, 'min_data_in_leaf': 37, 'feature_fraction': 0.747967084769148, 'bagging_fraction': 0.775340955911425, 'bagging_freq': 9, 'min_gain_to_split': 1.418714839423476, 'lambda_l1': 0.00394498613214936, 'lambda_l2': 0.00011225358676351021}. Best is trial 4 with value: 0.20130416998244618.\n",
            "[I 2025-09-04 13:32:47,911] Trial 5 finished with value: 0.20637278870210948 and parameters: {'learning_rate': 0.011567917945422095, 'num_leaves': 91, 'min_data_in_leaf': 62, 'feature_fraction': 0.8505432208537544, 'bagging_fraction': 0.9480009438738175, 'bagging_freq': 1, 'min_gain_to_split': 2.85859231443777, 'lambda_l1': 1.1389547708485317e-08, 'lambda_l2': 2.6724666562682014e-07}. Best is trial 4 with value: 0.20130416998244618.\n",
            "[I 2025-09-04 13:32:48,424] Trial 6 finished with value: 0.1942834516186389 and parameters: {'learning_rate': 0.039152968229584424, 'num_leaves': 55, 'min_data_in_leaf': 33, 'feature_fraction': 0.7271829042452481, 'bagging_fraction': 0.9811141095614457, 'bagging_freq': 4, 'min_gain_to_split': 0.5484904632425914, 'lambda_l1': 3.0606122696526286e-06, 'lambda_l2': 0.00036956725625487025}. Best is trial 6 with value: 0.1942834516186389.\n",
            "[I 2025-09-04 13:32:48,820] Trial 7 finished with value: 0.19924625199592125 and parameters: {'learning_rate': 0.047787182126190014, 'num_leaves': 89, 'min_data_in_leaf': 87, 'feature_fraction': 0.838748626762625, 'bagging_fraction': 0.8202666858192524, 'bagging_freq': 10, 'min_gain_to_split': 0.7413319586953494, 'lambda_l1': 0.017163003908861288, 'lambda_l2': 0.0051761487273114274}. Best is trial 6 with value: 0.1942834516186389.\n",
            "[I 2025-09-04 13:32:49,182] Trial 8 finished with value: 0.20935838565070627 and parameters: {'learning_rate': 0.030746013757131808, 'num_leaves': 88, 'min_data_in_leaf': 65, 'feature_fraction': 0.7296825930179496, 'bagging_fraction': 0.831545167153911, 'bagging_freq': 10, 'min_gain_to_split': 2.881432885499013, 'lambda_l1': 0.0013856355751528213, 'lambda_l2': 1.3135235028244436e-06}. Best is trial 6 with value: 0.1942834516186389.\n",
            "[I 2025-09-04 13:32:49,860] Trial 9 finished with value: 0.20466810282554598 and parameters: {'learning_rate': 0.028230434954597813, 'num_leaves': 113, 'min_data_in_leaf': 38, 'feature_fraction': 0.6057584412387674, 'bagging_fraction': 0.9541052795247591, 'bagging_freq': 1, 'min_gain_to_split': 2.603570869381119, 'lambda_l1': 0.018957800098662006, 'lambda_l2': 0.006412476093625099}. Best is trial 6 with value: 0.1942834516186389.\n",
            "[I 2025-09-04 13:32:50,500] Trial 10 finished with value: 0.18935267378768014 and parameters: {'learning_rate': 0.07589543640479057, 'num_leaves': 31, 'min_data_in_leaf': 115, 'feature_fraction': 0.654341076209669, 'bagging_fraction': 0.9981020175211902, 'bagging_freq': 4, 'min_gain_to_split': 0.024045648125228802, 'lambda_l1': 2.4884637328343367e-05, 'lambda_l2': 0.9979958556473273}. Best is trial 10 with value: 0.18935267378768014.\n",
            "[I 2025-09-04 13:32:51,725] Trial 11 finished with value: 0.18636921112237118 and parameters: {'learning_rate': 0.07454056002455112, 'num_leaves': 32, 'min_data_in_leaf': 117, 'feature_fraction': 0.6537106096337194, 'bagging_fraction': 0.9922665302781647, 'bagging_freq': 4, 'min_gain_to_split': 0.008315337056862493, 'lambda_l1': 2.4158223132893162e-05, 'lambda_l2': 0.9036987688786495}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:52,137] Trial 12 finished with value: 0.19550334920453089 and parameters: {'learning_rate': 0.0787782222934902, 'num_leaves': 32, 'min_data_in_leaf': 119, 'feature_fraction': 0.6365416295079391, 'bagging_fraction': 0.8942750372563524, 'bagging_freq': 4, 'min_gain_to_split': 0.1697033454917854, 'lambda_l1': 0.00010001368777409146, 'lambda_l2': 0.8752799614679709}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:52,621] Trial 13 finished with value: 0.1918388623930248 and parameters: {'learning_rate': 0.07439794213200326, 'num_leaves': 31, 'min_data_in_leaf': 120, 'feature_fraction': 0.6553517511932875, 'bagging_fraction': 0.9981977509119208, 'bagging_freq': 4, 'min_gain_to_split': 0.05275214109539636, 'lambda_l1': 9.959991969418328e-05, 'lambda_l2': 0.6982038929228299}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:52,972] Trial 14 finished with value: 0.20437895328053327 and parameters: {'learning_rate': 0.06043888078126196, 'num_leaves': 45, 'min_data_in_leaf': 104, 'feature_fraction': 0.670751151871586, 'bagging_fraction': 0.7105494088278299, 'bagging_freq': 6, 'min_gain_to_split': 1.0275307150813209, 'lambda_l1': 0.45637718968397295, 'lambda_l2': 0.06385665765898309}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:53,359] Trial 15 finished with value: 0.19725503466653638 and parameters: {'learning_rate': 0.06052043732390939, 'num_leaves': 43, 'min_data_in_leaf': 100, 'feature_fraction': 0.6836632156850753, 'bagging_fraction': 0.8979283514927158, 'bagging_freq': 6, 'min_gain_to_split': 0.4731090406091818, 'lambda_l1': 5.6613494673254746e-05, 'lambda_l2': 0.02429924858694839}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:53,837] Trial 16 finished with value: 0.20205652634092472 and parameters: {'learning_rate': 0.030680162931846444, 'num_leaves': 41, 'min_data_in_leaf': 105, 'feature_fraction': 0.6105303354652898, 'bagging_fraction': 0.8911693996012218, 'bagging_freq': 3, 'min_gain_to_split': 1.168723394440731, 'lambda_l1': 3.225564251836463e-07, 'lambda_l2': 0.1244675123133829}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:54,230] Trial 17 finished with value: 0.20297844278990626 and parameters: {'learning_rate': 0.0632334746268568, 'num_leaves': 126, 'min_data_in_leaf': 86, 'feature_fraction': 0.6925373099688359, 'bagging_fraction': 0.9978223626107784, 'bagging_freq': 3, 'min_gain_to_split': 1.8152133050253583, 'lambda_l1': 2.7066592089132214e-05, 'lambda_l2': 0.0028241565744254234}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:54,947] Trial 18 finished with value: 0.19690209474937231 and parameters: {'learning_rate': 0.0220454083142551, 'num_leaves': 50, 'min_data_in_leaf': 110, 'feature_fraction': 0.6267183809177377, 'bagging_fraction': 0.8691749724016733, 'bagging_freq': 5, 'min_gain_to_split': 0.32332311671085, 'lambda_l1': 0.0011380968355023658, 'lambda_l2': 2.168666358225693e-05}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:55,294] Trial 19 finished with value: 0.19837966970640167 and parameters: {'learning_rate': 0.07884173668555562, 'num_leaves': 37, 'min_data_in_leaf': 94, 'feature_fraction': 0.7981966029395882, 'bagging_fraction': 0.9164567848595128, 'bagging_freq': 2, 'min_gain_to_split': 0.8881973345354359, 'lambda_l1': 1.2816316816356427e-07, 'lambda_l2': 0.2703317132474648}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:58,193] Trial 20 finished with value: 0.18801666945116693 and parameters: {'learning_rate': 0.038436250070621424, 'num_leaves': 105, 'min_data_in_leaf': 114, 'feature_fraction': 0.8954582158843809, 'bagging_fraction': 0.9705598804531552, 'bagging_freq': 5, 'min_gain_to_split': 0.01981417142948243, 'lambda_l1': 0.0006003305548833565, 'lambda_l2': 4.114827685379422e-06}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:59,010] Trial 21 finished with value: 0.19189267461072615 and parameters: {'learning_rate': 0.050777554028387066, 'num_leaves': 101, 'min_data_in_leaf': 113, 'feature_fraction': 0.7921194210231586, 'bagging_fraction': 0.9701004302664292, 'bagging_freq': 5, 'min_gain_to_split': 0.06817067479818462, 'lambda_l1': 0.0004945917450335914, 'lambda_l2': 8.157579461679852e-06}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:32:59,567] Trial 22 finished with value: 0.19829415287512078 and parameters: {'learning_rate': 0.03721242904114396, 'num_leaves': 111, 'min_data_in_leaf': 112, 'feature_fraction': 0.8992433905925655, 'bagging_fraction': 0.9746563014677001, 'bagging_freq': 7, 'min_gain_to_split': 0.5817339124752895, 'lambda_l1': 2.2678620385322882e-05, 'lambda_l2': 3.5194915807298996e-06}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:00,033] Trial 23 finished with value: 0.1919288519778949 and parameters: {'learning_rate': 0.06133965749605376, 'num_leaves': 105, 'min_data_in_leaf': 21, 'feature_fraction': 0.8853467274270581, 'bagging_fraction': 0.9257013551098435, 'bagging_freq': 3, 'min_gain_to_split': 0.32794494740926566, 'lambda_l1': 0.00019632296650599386, 'lambda_l2': 0.02647141980539646}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:00,470] Trial 24 finished with value: 0.1938752362056951 and parameters: {'learning_rate': 0.06733484417462066, 'num_leaves': 126, 'min_data_in_leaf': 96, 'feature_fraction': 0.6961614579134494, 'bagging_fraction': 0.9995076815286155, 'bagging_freq': 5, 'min_gain_to_split': 0.29273855936233484, 'lambda_l1': 1.1258288636066153e-05, 'lambda_l2': 1.6756418179126462e-05}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:01,179] Trial 25 finished with value: 0.19078796492491962 and parameters: {'learning_rate': 0.05180532747020359, 'num_leaves': 97, 'min_data_in_leaf': 120, 'feature_fraction': 0.6613367306165475, 'bagging_fraction': 0.9662315969736072, 'bagging_freq': 6, 'min_gain_to_split': 0.03326389585426222, 'lambda_l1': 7.575291733961253e-07, 'lambda_l2': 0.0007790137871627885}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:01,758] Trial 26 finished with value: 0.20063761421217335 and parameters: {'learning_rate': 0.024429311971646824, 'num_leaves': 65, 'min_data_in_leaf': 81, 'feature_fraction': 0.632634189956786, 'bagging_fraction': 0.9270811249137264, 'bagging_freq': 4, 'min_gain_to_split': 1.2938302711647824, 'lambda_l1': 0.0005243164922072021, 'lambda_l2': 6.95492353922168e-05}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:02,231] Trial 27 finished with value: 0.1989714055972644 and parameters: {'learning_rate': 0.04291703318414037, 'num_leaves': 82, 'min_data_in_leaf': 111, 'feature_fraction': 0.7089676934528637, 'bagging_fraction': 0.9754686197878993, 'bagging_freq': 2, 'min_gain_to_split': 0.7473345321005044, 'lambda_l1': 0.005335114949738447, 'lambda_l2': 0.2844141044528847}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:02,883] Trial 28 finished with value: 0.20349037377298013 and parameters: {'learning_rate': 0.016974360772603926, 'num_leaves': 118, 'min_data_in_leaf': 92, 'feature_fraction': 0.7751886105769271, 'bagging_fraction': 0.9105873717024253, 'bagging_freq': 7, 'min_gain_to_split': 1.6834597462368004, 'lambda_l1': 0.2071591686895945, 'lambda_l2': 0.015808466289907907}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:03,484] Trial 29 finished with value: 0.1975941882388926 and parameters: {'learning_rate': 0.033146203860885126, 'num_leaves': 69, 'min_data_in_leaf': 103, 'feature_fraction': 0.7627187017715594, 'bagging_fraction': 0.8698525171850366, 'bagging_freq': 7, 'min_gain_to_split': 0.44855306066352146, 'lambda_l1': 7.844708402952553e-06, 'lambda_l2': 9.140277463206276e-08}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:03,866] Trial 30 finished with value: 0.19875474186133135 and parameters: {'learning_rate': 0.06814998356044229, 'num_leaves': 36, 'min_data_in_leaf': 108, 'feature_fraction': 0.816890871505487, 'bagging_fraction': 0.9567291875416024, 'bagging_freq': 5, 'min_gain_to_split': 0.7088967164377197, 'lambda_l1': 9.612311680651123e-08, 'lambda_l2': 1.7235838752715595e-08}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:05,178] Trial 31 finished with value: 0.1871882082158869 and parameters: {'learning_rate': 0.053934994819901126, 'num_leaves': 98, 'min_data_in_leaf': 120, 'feature_fraction': 0.6515526523385965, 'bagging_fraction': 0.9685179328748582, 'bagging_freq': 6, 'min_gain_to_split': 0.012376427075121162, 'lambda_l1': 1.293134582610096e-06, 'lambda_l2': 0.0007146120516961952}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:05,682] Trial 32 finished with value: 0.19490837638971542 and parameters: {'learning_rate': 0.05333922660050933, 'num_leaves': 96, 'min_data_in_leaf': 115, 'feature_fraction': 0.6594101741746244, 'bagging_fraction': 0.9875389354000775, 'bagging_freq': 6, 'min_gain_to_split': 0.20490868875721713, 'lambda_l1': 1.454276650399675e-06, 'lambda_l2': 0.1003395150586459}. Best is trial 11 with value: 0.18636921112237118.\n",
            "[I 2025-09-04 13:33:07,416] Trial 33 finished with value: 0.1858601054403874 and parameters: {'learning_rate': 0.04348705588913312, 'num_leaves': 112, 'min_data_in_leaf': 101, 'feature_fraction': 0.6430577268959782, 'bagging_fraction': 0.9423061110056787, 'bagging_freq': 4, 'min_gain_to_split': 0.01538417746182449, 'lambda_l1': 6.191684398292768e-06, 'lambda_l2': 2.862492070348498e-06}. Best is trial 33 with value: 0.1858601054403874.\n",
            "[I 2025-09-04 13:33:07,924] Trial 34 finished with value: 0.19439838565233758 and parameters: {'learning_rate': 0.044068515501412275, 'num_leaves': 108, 'min_data_in_leaf': 100, 'feature_fraction': 0.631358656149008, 'bagging_fraction': 0.9373149092096079, 'bagging_freq': 3, 'min_gain_to_split': 0.2671835482558911, 'lambda_l1': 4.510896476360913e-06, 'lambda_l2': 1.6068011310980292e-06}. Best is trial 33 with value: 0.1858601054403874.\n",
            "[I 2025-09-04 13:33:08,503] Trial 35 finished with value: 0.19687524202388915 and parameters: {'learning_rate': 0.03584073087170648, 'num_leaves': 119, 'min_data_in_leaf': 107, 'feature_fraction': 0.8703561524633291, 'bagging_fraction': 0.9407878564763874, 'bagging_freq': 8, 'min_gain_to_split': 0.42618275272368855, 'lambda_l1': 5.534810557846105e-07, 'lambda_l2': 4.5388226037572463e-07}. Best is trial 33 with value: 0.1858601054403874.\n",
            "[I 2025-09-04 13:33:13,581] Trial 36 finished with value: 0.18263267702820873 and parameters: {'learning_rate': 0.0552373780223355, 'num_leaves': 104, 'min_data_in_leaf': 73, 'feature_fraction': 0.6789918309338988, 'bagging_fraction': 0.95822359376646, 'bagging_freq': 5, 'min_gain_to_split': 0.0020799207826429564, 'lambda_l1': 8.118125288778721e-08, 'lambda_l2': 5.432970576021396e-05}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:14,094] Trial 37 finished with value: 0.19245070798925656 and parameters: {'learning_rate': 0.05627864265668811, 'num_leaves': 80, 'min_data_in_leaf': 73, 'feature_fraction': 0.6744704732978898, 'bagging_fraction': 0.8013610946616008, 'bagging_freq': 2, 'min_gain_to_split': 0.19358573198963341, 'lambda_l1': 6.350007568887003e-08, 'lambda_l2': 5.488218685233105e-05}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:14,481] Trial 38 finished with value: 0.20511759439975755 and parameters: {'learning_rate': 0.043299184791267646, 'num_leaves': 117, 'min_data_in_leaf': 57, 'feature_fraction': 0.7083521953179984, 'bagging_fraction': 0.9601588007422939, 'bagging_freq': 7, 'min_gain_to_split': 2.3451433285994847, 'lambda_l1': 4.841845718595282e-08, 'lambda_l2': 0.0010732796275911601}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:14,933] Trial 39 finished with value: 0.1979588554043729 and parameters: {'learning_rate': 0.04739997791173726, 'num_leaves': 94, 'min_data_in_leaf': 49, 'feature_fraction': 0.6171634288494274, 'bagging_fraction': 0.8712557904888194, 'bagging_freq': 4, 'min_gain_to_split': 0.9373656307123895, 'lambda_l1': 2.1366947363754285e-06, 'lambda_l2': 0.00010846850921891593}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:15,351] Trial 40 finished with value: 0.19798349930713696 and parameters: {'learning_rate': 0.06894532720239524, 'num_leaves': 85, 'min_data_in_leaf': 72, 'feature_fraction': 0.7354183618226454, 'bagging_fraction': 0.7309957571060455, 'bagging_freq': 6, 'min_gain_to_split': 0.5980478521279182, 'lambda_l1': 9.187834902975578e-07, 'lambda_l2': 3.349505101645619e-05}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:16,012] Trial 41 finished with value: 0.1935726782672555 and parameters: {'learning_rate': 0.0388838005979238, 'num_leaves': 102, 'min_data_in_leaf': 117, 'feature_fraction': 0.6444720038097078, 'bagging_fraction': 0.945119713444142, 'bagging_freq': 5, 'min_gain_to_split': 0.11567325605184589, 'lambda_l1': 1.7623095369398677e-07, 'lambda_l2': 1.8015396460980731e-06}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:16,444] Trial 42 finished with value: 0.19445115477865935 and parameters: {'learning_rate': 0.05639080011033049, 'num_leaves': 107, 'min_data_in_leaf': 97, 'feature_fraction': 0.6770637406518241, 'bagging_fraction': 0.9813219835275647, 'bagging_freq': 5, 'min_gain_to_split': 0.3828340318390553, 'lambda_l1': 8.402040381042994e-06, 'lambda_l2': 6.830412604855778e-06}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:18,146] Trial 43 finished with value: 0.19213270740768412 and parameters: {'learning_rate': 0.010535284060544024, 'num_leaves': 73, 'min_data_in_leaf': 87, 'feature_fraction': 0.6475661478112837, 'bagging_fraction': 0.961462459986367, 'bagging_freq': 4, 'min_gain_to_split': 0.18846950404673285, 'lambda_l1': 4.1661684292882015e-08, 'lambda_l2': 0.0002294325782978061}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:18,956] Trial 44 finished with value: 0.18845829571229628 and parameters: {'learning_rate': 0.04451225325788574, 'num_leaves': 111, 'min_data_in_leaf': 78, 'feature_fraction': 0.7105922834372872, 'bagging_fraction': 0.9310380720243749, 'bagging_freq': 8, 'min_gain_to_split': 0.04678031511765293, 'lambda_l1': 1.618733580667307e-08, 'lambda_l2': 1.420364092881356e-07}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:20,105] Trial 45 finished with value: 0.18867776124936322 and parameters: {'learning_rate': 0.03418347678104479, 'num_leaves': 98, 'min_data_in_leaf': 114, 'feature_fraction': 0.6025038162766516, 'bagging_fraction': 0.9824957134797352, 'bagging_freq': 4, 'min_gain_to_split': 0.024853651205973357, 'lambda_l1': 3.635653437016883e-06, 'lambda_l2': 9.126961717823825e-06}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:20,565] Trial 46 finished with value: 0.19437781039949611 and parameters: {'learning_rate': 0.04878162686336359, 'num_leaves': 91, 'min_data_in_leaf': 66, 'feature_fraction': 0.6200118925473479, 'bagging_fraction': 0.950622590304081, 'bagging_freq': 5, 'min_gain_to_split': 0.5500896812065803, 'lambda_l1': 0.00021279704482810748, 'lambda_l2': 7.183913414718429e-07}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:21,362] Trial 47 finished with value: 0.19441863989191624 and parameters: {'learning_rate': 0.02736944389561174, 'num_leaves': 102, 'min_data_in_leaf': 101, 'feature_fraction': 0.6919318992084881, 'bagging_fraction': 0.9065069538478282, 'bagging_freq': 6, 'min_gain_to_split': 0.21554923628442496, 'lambda_l1': 4.198262798961434e-07, 'lambda_l2': 0.00019966463336791468}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:21,778] Trial 48 finished with value: 0.20303510190632962 and parameters: {'learning_rate': 0.04086783044534725, 'num_leaves': 121, 'min_data_in_leaf': 50, 'feature_fraction': 0.749081376220413, 'bagging_fraction': 0.9894440208676109, 'bagging_freq': 3, 'min_gain_to_split': 1.9862462323442431, 'lambda_l1': 0.005400489626055451, 'lambda_l2': 3.5755614793105335e-06}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:26,991] Trial 49 finished with value: 0.1850385028613791 and parameters: {'learning_rate': 0.05700042031353487, 'num_leaves': 115, 'min_data_in_leaf': 120, 'feature_fraction': 0.6660600592298008, 'bagging_fraction': 0.9664575882652953, 'bagging_freq': 4, 'min_gain_to_split': 5.742455887433433e-05, 'lambda_l1': 4.150001761553577e-05, 'lambda_l2': 0.000748353869565967}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:27,456] Trial 50 finished with value: 0.19544964325670744 and parameters: {'learning_rate': 0.07225389550072871, 'num_leaves': 114, 'min_data_in_leaf': 120, 'feature_fraction': 0.6643332339300986, 'bagging_fraction': 0.8364761629776215, 'bagging_freq': 4, 'min_gain_to_split': 0.16223173422329779, 'lambda_l1': 2.5463477254769508e-05, 'lambda_l2': 0.0018961713075555016}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:27,906] Trial 51 finished with value: 0.19609248978494884 and parameters: {'learning_rate': 0.05513656350216473, 'num_leaves': 105, 'min_data_in_leaf': 109, 'feature_fraction': 0.6418129965461747, 'bagging_fraction': 0.9663314790762285, 'bagging_freq': 5, 'min_gain_to_split': 0.3456558858671339, 'lambda_l1': 7.096698576931185e-05, 'lambda_l2': 0.00043356492935677}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:30,576] Trial 52 finished with value: 0.18495006406384557 and parameters: {'learning_rate': 0.06331498924118771, 'num_leaves': 59, 'min_data_in_leaf': 117, 'feature_fraction': 0.6513300975017356, 'bagging_fraction': 0.9515030377945897, 'bagging_freq': 4, 'min_gain_to_split': 0.005582519693517019, 'lambda_l1': 0.00020042215514419265, 'lambda_l2': 0.004469078986082893}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:31,044] Trial 53 finished with value: 0.1943108759337046 and parameters: {'learning_rate': 0.062321949310321985, 'num_leaves': 76, 'min_data_in_leaf': 117, 'feature_fraction': 0.6828113477051629, 'bagging_fraction': 0.9486224796661639, 'bagging_freq': 3, 'min_gain_to_split': 0.14787710847911495, 'lambda_l1': 4.8010652885489754e-05, 'lambda_l2': 0.0040025107976196204}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:31,539] Trial 54 finished with value: 0.19760016397579885 and parameters: {'learning_rate': 0.057713513152351195, 'num_leaves': 52, 'min_data_in_leaf': 107, 'feature_fraction': 0.6642882311378495, 'bagging_fraction': 0.9194627675309217, 'bagging_freq': 4, 'min_gain_to_split': 0.47144199347881804, 'lambda_l1': 0.00017056241616440114, 'lambda_l2': 0.00872508693096116}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:32,645] Trial 55 finished with value: 0.18495863656265638 and parameters: {'learning_rate': 0.06486988416594897, 'num_leaves': 57, 'min_data_in_leaf': 89, 'feature_fraction': 0.650530663181354, 'bagging_fraction': 0.940078971663893, 'bagging_freq': 3, 'min_gain_to_split': 0.015905939276415912, 'lambda_l1': 9.108173749166784e-06, 'lambda_l2': 0.0007992284312997827}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:33,065] Trial 56 finished with value: 0.19420094536688565 and parameters: {'learning_rate': 0.06533893259237257, 'num_leaves': 60, 'min_data_in_leaf': 88, 'feature_fraction': 0.6268762762141288, 'bagging_fraction': 0.8861021357026622, 'bagging_freq': 2, 'min_gain_to_split': 0.27380385981585303, 'lambda_l1': 9.70499472186853e-06, 'lambda_l2': 0.0021974687951570606}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:33,466] Trial 57 finished with value: 0.19660553404483266 and parameters: {'learning_rate': 0.07375827268498167, 'num_leaves': 60, 'min_data_in_leaf': 91, 'feature_fraction': 0.6410693205398215, 'bagging_fraction': 0.9354333642584518, 'bagging_freq': 3, 'min_gain_to_split': 0.6450073509614866, 'lambda_l1': 0.001983661393754867, 'lambda_l2': 0.00019427267612122945}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:33,911] Trial 58 finished with value: 0.19137165196327593 and parameters: {'learning_rate': 0.07102592346518644, 'num_leaves': 48, 'min_data_in_leaf': 83, 'feature_fraction': 0.6143811984656325, 'bagging_fraction': 0.988664576273338, 'bagging_freq': 4, 'min_gain_to_split': 0.12027575225500284, 'lambda_l1': 2.158409926049307e-05, 'lambda_l2': 0.009104166683423755}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:38,022] Trial 59 finished with value: 0.18487499460969253 and parameters: {'learning_rate': 0.07857630122411004, 'num_leaves': 57, 'min_data_in_leaf': 104, 'feature_fraction': 0.6978743739897779, 'bagging_fraction': 0.9023063881179633, 'bagging_freq': 1, 'min_gain_to_split': 0.005156410916122654, 'lambda_l1': 4.575010208297515e-05, 'lambda_l2': 0.0004844989168778637}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:38,948] Trial 60 finished with value: 0.1944559530527065 and parameters: {'learning_rate': 0.04701645913210794, 'num_leaves': 65, 'min_data_in_leaf': 97, 'feature_fraction': 0.7202016582905595, 'bagging_fraction': 0.9065588272126923, 'bagging_freq': 1, 'min_gain_to_split': 0.3775227987541406, 'lambda_l1': 0.0001083357713554633, 'lambda_l2': 0.001493191297149516}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:39,870] Trial 61 finished with value: 0.19268190334281848 and parameters: {'learning_rate': 0.07851115921340389, 'num_leaves': 58, 'min_data_in_leaf': 104, 'feature_fraction': 0.6705480644307756, 'bagging_fraction': 0.9558230044599545, 'bagging_freq': 1, 'min_gain_to_split': 0.1171084056303991, 'lambda_l1': 4.1613939244291646e-05, 'lambda_l2': 0.00046309975702307977}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:41,265] Trial 62 finished with value: 0.1839907187945832 and parameters: {'learning_rate': 0.06491260304583779, 'num_leaves': 54, 'min_data_in_leaf': 78, 'feature_fraction': 0.6965704938778392, 'bagging_fraction': 0.9205042385907957, 'bagging_freq': 2, 'min_gain_to_split': 0.01513742715714614, 'lambda_l1': 1.1676020919031635e-05, 'lambda_l2': 0.04910353255578541}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:41,816] Trial 63 finished with value: 0.19370464557745687 and parameters: {'learning_rate': 0.059862574719893355, 'num_leaves': 55, 'min_data_in_leaf': 77, 'feature_fraction': 0.6895950273015339, 'bagging_fraction': 0.8848696139598538, 'bagging_freq': 2, 'min_gain_to_split': 0.2647070298563442, 'lambda_l1': 0.0002664506105863254, 'lambda_l2': 0.03639293102362074}. Best is trial 36 with value: 0.18263267702820873.\n",
            "[I 2025-09-04 13:33:44,893] Trial 64 finished with value: 0.18246085847790522 and parameters: {'learning_rate': 0.0643313404097897, 'num_leaves': 53, 'min_data_in_leaf': 70, 'feature_fraction': 0.6972048201585458, 'bagging_fraction': 0.9206658571484022, 'bagging_freq': 1, 'min_gain_to_split': 0.001996946188143104, 'lambda_l1': 1.5863435468056973e-05, 'lambda_l2': 0.005004053354475371}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:45,611] Trial 65 finished with value: 0.1895181048803912 and parameters: {'learning_rate': 0.06489116736185127, 'num_leaves': 46, 'min_data_in_leaf': 69, 'feature_fraction': 0.7034060313253374, 'bagging_fraction': 0.9183325611255811, 'bagging_freq': 1, 'min_gain_to_split': 0.10421913686745446, 'lambda_l1': 1.522308965346102e-05, 'lambda_l2': 0.004693048979397255}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:46,494] Trial 66 finished with value: 0.1919454678294565 and parameters: {'learning_rate': 0.06603880512415594, 'num_leaves': 57, 'min_data_in_leaf': 61, 'feature_fraction': 0.7302196259348724, 'bagging_fraction': 0.8998767292904244, 'bagging_freq': 1, 'min_gain_to_split': 0.2754194729835695, 'lambda_l1': 2.7699137237306886e-06, 'lambda_l2': 0.01756478696748467}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:46,849] Trial 67 finished with value: 0.20655714930918742 and parameters: {'learning_rate': 0.059245597706691425, 'num_leaves': 51, 'min_data_in_leaf': 74, 'feature_fraction': 0.7168151676227807, 'bagging_fraction': 0.9282821329788411, 'bagging_freq': 2, 'min_gain_to_split': 2.550158643693439, 'lambda_l1': 0.00012212101532698774, 'lambda_l2': 0.04624873093789366}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:47,456] Trial 68 finished with value: 0.1998554307356274 and parameters: {'learning_rate': 0.07654112899945457, 'num_leaves': 68, 'min_data_in_leaf': 66, 'feature_fraction': 0.7020462924315057, 'bagging_fraction': 0.9181207079978916, 'bagging_freq': 1, 'min_gain_to_split': 1.5370077012379888, 'lambda_l1': 0.00035437262579987057, 'lambda_l2': 0.0031030048568402298}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:50,077] Trial 69 finished with value: 0.19539724740177758 and parameters: {'learning_rate': 0.01431655773117676, 'num_leaves': 63, 'min_data_in_leaf': 83, 'feature_fraction': 0.7406806362332857, 'bagging_fraction': 0.8564636663882143, 'bagging_freq': 2, 'min_gain_to_split': 0.4936026061748928, 'lambda_l1': 6.80981920089856e-05, 'lambda_l2': 0.0008597412217015393}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:50,933] Trial 70 finished with value: 0.19123992839624118 and parameters: {'learning_rate': 0.050898843723668465, 'num_leaves': 39, 'min_data_in_leaf': 79, 'feature_fraction': 0.6804162814311909, 'bagging_fraction': 0.8792643459910273, 'bagging_freq': 2, 'min_gain_to_split': 0.114464394561832, 'lambda_l1': 1.3805519768200486e-05, 'lambda_l2': 0.00979297784472474}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:52,115] Trial 71 finished with value: 0.1842807754676345 and parameters: {'learning_rate': 0.06301668116036631, 'num_leaves': 43, 'min_data_in_leaf': 75, 'feature_fraction': 0.6548227796930375, 'bagging_fraction': 0.9418046460730379, 'bagging_freq': 3, 'min_gain_to_split': 0.015675824386315797, 'lambda_l1': 5.566004120262208e-06, 'lambda_l2': 0.0005659287015801499}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:53,202] Trial 72 finished with value: 0.18319925594669623 and parameters: {'learning_rate': 0.06960212324558741, 'num_leaves': 53, 'min_data_in_leaf': 62, 'feature_fraction': 0.6690440696061405, 'bagging_fraction': 0.9261274235830799, 'bagging_freq': 3, 'min_gain_to_split': 0.015999046508598527, 'lambda_l1': 3.640343379318242e-05, 'lambda_l2': 0.00031426774951401164}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:53,629] Trial 73 finished with value: 0.19154271114870713 and parameters: {'learning_rate': 0.07262674393399894, 'num_leaves': 43, 'min_data_in_leaf': 63, 'feature_fraction': 0.6549021632694989, 'bagging_fraction': 0.8985439463582104, 'bagging_freq': 3, 'min_gain_to_split': 0.2004249047389181, 'lambda_l1': 0.0011013724614804827, 'lambda_l2': 0.0003011172237496426}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:54,051] Trial 74 finished with value: 0.19357125944742223 and parameters: {'learning_rate': 0.06310776552058403, 'num_leaves': 55, 'min_data_in_leaf': 76, 'feature_fraction': 0.6860801139377516, 'bagging_fraction': 0.9252908874520783, 'bagging_freq': 3, 'min_gain_to_split': 0.3402777409270798, 'lambda_l1': 5.697155231492468e-06, 'lambda_l2': 0.00011472367577458797}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:56,870] Trial 75 finished with value: 0.18266837815915157 and parameters: {'learning_rate': 0.06959348754609682, 'num_leaves': 53, 'min_data_in_leaf': 71, 'feature_fraction': 0.6766663714967946, 'bagging_fraction': 0.9366293478581079, 'bagging_freq': 2, 'min_gain_to_split': 0.0023232615740860756, 'lambda_l1': 2.2662733795944916e-07, 'lambda_l2': 0.0013994636414610797}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:57,725] Trial 76 finished with value: 0.18880699041837734 and parameters: {'learning_rate': 0.06984112802637847, 'num_leaves': 53, 'min_data_in_leaf': 58, 'feature_fraction': 0.6984038996349867, 'bagging_fraction': 0.9093868091483674, 'bagging_freq': 1, 'min_gain_to_split': 0.10295516968732413, 'lambda_l1': 2.1099960765006467e-07, 'lambda_l2': 6.637955437110209e-05}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:58,141] Trial 77 finished with value: 0.19155394760823455 and parameters: {'learning_rate': 0.07989918272430309, 'num_leaves': 48, 'min_data_in_leaf': 71, 'feature_fraction': 0.6734953397512214, 'bagging_fraction': 0.9338914932971749, 'bagging_freq': 2, 'min_gain_to_split': 0.19681425326065022, 'lambda_l1': 1.5994172659711098e-08, 'lambda_l2': 0.0012498431268747597}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:58,537] Trial 78 finished with value: 0.19839937825020362 and parameters: {'learning_rate': 0.06999361426237882, 'num_leaves': 49, 'min_data_in_leaf': 54, 'feature_fraction': 0.6958325633929658, 'bagging_fraction': 0.9512213382088094, 'bagging_freq': 2, 'min_gain_to_split': 1.1407789068855523, 'lambda_l1': 2.79233760394412e-07, 'lambda_l2': 0.255961498911176}. Best is trial 64 with value: 0.18246085847790522.\n",
            "[I 2025-09-04 13:33:59,303] Trial 79 finished with value: 0.19320467543980419 and parameters: {'learning_rate': 0.07509654087085554, 'num_leaves': 41, 'min_data_in_leaf': 68, 'feature_fraction': 0.6833329247303079, 'bagging_fraction': 0.9138374811087703, 'bagging_freq': 1, 'min_gain_to_split': 0.4178867726274085, 'lambda_l1': 9.788997613872341e-08, 'lambda_l2': 2.455209078336735e-05}. Best is trial 64 with value: 0.18246085847790522.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OPTUNA] best RMSLE: 0.1825\n",
            "[OPTUNA] best params:\n",
            "  learning_rate: 0.0643313404097897\n",
            "  num_leaves: 53\n",
            "  min_data_in_leaf: 70\n",
            "  feature_fraction: 0.6972048201585458\n",
            "  bagging_fraction: 0.9206658571484022\n",
            "  bagging_freq: 1\n",
            "  min_gain_to_split: 0.001996946188143104\n",
            "  lambda_l1: 1.5863435468056973e-05\n",
            "  lambda_l2: 0.005004053354475371\n",
            "[OPTUNA] best_round: 333\n",
            "Saved models → models\n"
          ]
        }
      ]
    }
  ]
}