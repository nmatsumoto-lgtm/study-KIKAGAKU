{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNOyfkiJNpriNhDfsoo46Hp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmatsumoto-lgtm/study-KIKAGAKU/blob/main/%E4%B8%8D%E5%8B%95%E7%94%A3%E4%BE%A1%E6%A0%BC%E4%BA%88%E6%B8%AC%E3%82%A2%E3%83%97%E3%83%AA_Ver_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ecn2Ecyv-_Do"
      },
      "outputs": [],
      "source": [
        "!pip -q install lightgbm==4.5.0 optuna==3.6.1 joblib pandas numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "import json\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from joblib import dump"
      ],
      "metadata": {
        "id": "lLSnSHj3_Z-D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "eW4OJKbo_hIB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IN = Path(\"data/interim/train_tabular.csv\")\n",
        "OUT_DIR = Path(\"models\"); OUT_DIR.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "O15JAXWq_lwB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 1) データ読み込み & 追加特徴量\n",
        "# ============================\n",
        "\n",
        "def _oof_target_median(df: pd.DataFrame, key: str, y: np.ndarray, n_splits: int = 5) -> np.ndarray:\n",
        "    \"\"\"キー列ごとの OOF 中央値エンコーディング（リーク防止）。\n",
        "    戻り値は各行に対応する OOF 推定値（学習折ごとに学習外の中央値を使う）。\n",
        "    \"\"\"\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
        "    oof = np.zeros(len(df), dtype=float)\n",
        "    for tr_idx, va_idx in kf.split(df):\n",
        "        med = (\n",
        "            pd.DataFrame({key: df.iloc[tr_idx][key].values, \"y\": y[tr_idx]})\n",
        "            .groupby(key)[\"y\"].median()\n",
        "        )\n",
        "        oof[va_idx] = df.iloc[va_idx][key].map(med).fillna(med.median()).values\n",
        "    return oof\n",
        "\n",
        "\n",
        "def build_table_and_features() -> tuple[pd.DataFrame, list[str], list[str], list[str], list[int]]:\n",
        "    df = pd.read_csv(IN)\n",
        "\n",
        "    # ===== 対数ターゲット =====\n",
        "    y = df[\"price_yen\"].astype(float).values\n",
        "    y_log = np.log1p(y)\n",
        "\n",
        "    # ===== 追加特徴量 =====\n",
        "    df[\"access_score\"] = 1.0 / (1.0 + df[\"walk_min\"].astype(float))\n",
        "    df[\"sqrt_area\"] = np.sqrt(np.clip(df[\"area_sqm\"].astype(float), 0, None))\n",
        "    df[\"log_area\"] = np.log1p(np.clip(df[\"area_sqm\"].astype(float), 0, None))\n",
        "    df[\"age_sqrt\"] = np.sqrt(np.clip(df[\"築年数\"].astype(float), 0, None))\n",
        "    df[\"area_x_access\"] = df[\"area_sqm\"].astype(float) * df[\"access_score\"].astype(float)\n",
        "\n",
        "    # 頻度特徴量（全体集計）\n",
        "    station_cnt = df[\"station\"].value_counts()\n",
        "    layout_cnt  = df[\"layout\"].value_counts()\n",
        "    df[\"station_count\"] = df[\"station\"].map(station_cnt).fillna(0).astype(int)\n",
        "    df[\"layout_count\"]  = df[\"layout\"].map(layout_cnt).fillna(0).astype(int)\n",
        "\n",
        "    # OOF 目標エンコード（中央値）※対数ターゲットで作る\n",
        "    df[\"station_oof_median_log\"] = _oof_target_median(df, \"station\", y_log)\n",
        "    df[\"layout_oof_median_log\"]  = _oof_target_median(df, \"layout\",  y_log)\n",
        "\n",
        "    # --- 推論時に必要な「学習時の統計」を作っておく（新規データに同じ変換を適用するため）\n",
        "    station_med_map = (\n",
        "        pd.DataFrame({\"station\": df[\"station\"], \"y_log\": y_log})\n",
        "        .groupby(\"station\")[\"y_log\"].median().to_dict()\n",
        "    )\n",
        "    layout_med_map = (\n",
        "        pd.DataFrame({\"layout\": df[\"layout\"], \"y_log\": y_log})\n",
        "        .groupby(\"layout\")[\"y_log\"].median().to_dict()\n",
        "    )\n",
        "    global_station_med = float(np.median(list(station_med_map.values()))) if len(station_med_map) else float(np.median(y_log))\n",
        "    global_layout_med  = float(np.median(list(layout_med_map.values())))  if len(layout_med_map)  else float(np.median(y_log))\n",
        "\n",
        "    # カテゴリ列\n",
        "    feat_cat = [\"station\", \"layout\"]\n",
        "\n",
        "    # 数値列（順序固定）\n",
        "    feat_num_base = [\"walk_min\", \"築年数\", \"area_sqm\"]\n",
        "    feat_num_extra = [\n",
        "        \"access_score\", \"sqrt_area\", \"log_area\", \"age_sqrt\",\n",
        "        \"area_x_access\", \"station_count\", \"layout_count\",\n",
        "        \"station_oof_median_log\", \"layout_oof_median_log\",\n",
        "    ]\n",
        "    feat_num_all = feat_num_base + feat_num_extra\n",
        "\n",
        "    # 単調性制約（[cat..., num...] の順で並ぶことに注意）\n",
        "    n_cat = len(feat_cat)\n",
        "    mono_num = [-1, -1, +1] + [0] * (len(feat_num_all) - 3)\n",
        "    monotone_constraints = [0] * n_cat + mono_num\n",
        "\n",
        "    # ====== エンコードして学習用テーブルを構成 ======\n",
        "    oe = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
        "    X_cat = oe.fit_transform(df[feat_cat].fillna(\"NA\")).astype(\"int32\")\n",
        "    X_num = df[feat_num_all].astype(float).values\n",
        "    X = np.hstack([X_cat, X_num])\n",
        "\n",
        "    cat_cols = [f\"cat__{c}\" for c in feat_cat]\n",
        "    num_cols = feat_num_all.copy()\n",
        "    X_df = pd.DataFrame(X, columns=cat_cols + num_cols)\n",
        "    categorical_feature = cat_cols\n",
        "\n",
        "    meta = {\n",
        "        \"feat_cat\": feat_cat,\n",
        "        \"feat_num\": num_cols,\n",
        "        \"categorical_feature\": categorical_feature,\n",
        "        \"monotone_constraints\": monotone_constraints,\n",
        "    }\n",
        "\n",
        "    # ★ 推論用マップ（統計 + 列順）をまとめて返す\n",
        "    infer_maps = {\n",
        "        \"station_count_map\": station_cnt.to_dict(),\n",
        "        \"layout_count_map\": layout_cnt.to_dict(),\n",
        "        \"station_median_log_map\": station_med_map,\n",
        "        \"layout_median_log_map\": layout_med_map,\n",
        "        \"global_station_median_log\": global_station_med,\n",
        "        \"global_layout_median_log\": global_layout_med,\n",
        "        \"feat_cat\": feat_cat,\n",
        "        \"feat_num\": num_cols,\n",
        "    }\n",
        "\n",
        "    # ★ 返り値に infer_maps を追加（＝合計7つ）\n",
        "    return X_df, y_log, categorical_feature, monotone_constraints, meta, oe, infer_maps\n"
      ],
      "metadata": {
        "id": "eJwZjsfFADw0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 2) Optuna でハイパラ探索\n",
        "# ============================\n",
        "\n",
        "def tune_with_optuna(\n",
        "    X_df: pd.DataFrame,\n",
        "    y_log: np.ndarray,\n",
        "    categorical_feature: list[str],\n",
        "    monotone_constraints: list[int],\n",
        "    n_trials: int = 80,\n",
        ") -> tuple[dict, int, float]:\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "\n",
        "    def objective(trial: optuna.Trial) -> float:\n",
        "        params = {\n",
        "            \"objective\": \"rmse\",  # 対数価格の RMSE → RMSLE 等価\n",
        "            \"metric\": \"rmse\",\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
        "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\n",
        "            \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 200),\n",
        "            \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
        "            \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
        "            \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 10),\n",
        "            \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 5.0),\n",
        "            \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
        "            \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
        "            \"verbosity\": -1,\n",
        "            \"seed\": SEED,\n",
        "            \"monotone_constraints\": monotone_constraints,\n",
        "        }\n",
        "        rmsles = []\n",
        "        best_iters = []\n",
        "        for tr_idx, va_idx in kf.split(X_df):\n",
        "            X_tr, X_va = X_df.iloc[tr_idx], X_df.iloc[va_idx]\n",
        "            y_tr, y_va = y_log[tr_idx], y_log[va_idx]\n",
        "            dtr = lgb.Dataset(X_tr, label=y_tr, categorical_feature=categorical_feature, free_raw_data=True)\n",
        "            dva = lgb.Dataset(X_va, label=y_va, categorical_feature=categorical_feature, free_raw_data=True)\n",
        "\n",
        "            model = lgb.train(\n",
        "                params,\n",
        "                dtr,\n",
        "                valid_sets=[dva],\n",
        "                num_boost_round=4000,\n",
        "                callbacks=[lgb.early_stopping(200, verbose=False)],\n",
        "            )\n",
        "            pred_log = model.predict(X_va, num_iteration=model.best_iteration)\n",
        "            # y_log の RMSE = RMSLE（expm1 に戻した価格に対する）\n",
        "            rmsle = float(np.sqrt(mean_squared_log_error(np.expm1(y_va), np.expm1(pred_log))))\n",
        "            rmsles.append(rmsle)\n",
        "            best_iters.append(model.best_iteration)\n",
        "        trial.set_user_attr(\"best_iters\", best_iters)\n",
        "        return float(np.mean(rmsles))\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    # CV で選ばれた best_iteration を平均化\n",
        "    best_iters_list = study.best_trial.user_attrs.get(\"best_iters\", [1000])\n",
        "    best_round = int(np.clip(np.mean(best_iters_list), 100, 4000))\n",
        "    best_score = study.best_value\n",
        "    return best_params, best_round, best_score"
      ],
      "metadata": {
        "id": "Pb67dPghADsc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 3) 最終学習（ポイント & 分位点）\n",
        "# ============================\n",
        "\n",
        "def train_final_models(\n",
        "    X_df: pd.DataFrame,\n",
        "    y_log: np.ndarray,\n",
        "    categorical_feature: list[str],\n",
        "    monotone_constraints: list[int],\n",
        "    best_params: dict,\n",
        "    best_round: int,\n",
        "):\n",
        "    base_params = dict(best_params)\n",
        "    base_params.update({\n",
        "        \"objective\": \"rmse\",\n",
        "        \"metric\": \"rmse\",\n",
        "        \"verbosity\": -1,\n",
        "        \"seed\": SEED,\n",
        "        # ★ ポイントモデルでは単調性制約を使う\n",
        "        \"monotone_constraints\": monotone_constraints,\n",
        "    })\n",
        "\n",
        "    # 生データを解放しない（categorical_feature を後で使えるように）\n",
        "    dtrain = lgb.Dataset(\n",
        "        X_df,\n",
        "        label=y_log,\n",
        "        categorical_feature=categorical_feature,\n",
        "        free_raw_data=False\n",
        "    )\n",
        "\n",
        "    # ---- ポイント（対数価格）----\n",
        "    model_point = lgb.train(base_params, dtrain, num_boost_round=best_round)\n",
        "\n",
        "    # ---- 分位点（q10/q90）----\n",
        "    models_q = {}\n",
        "    for alpha, tag in [(0.1, \"q10\"), (0.9, \"q90\")]:\n",
        "        q_params = dict(best_params)\n",
        "        q_params.update({\n",
        "            \"objective\": \"quantile\",\n",
        "            \"alpha\": alpha,\n",
        "            \"metric\": \"quantile\",\n",
        "            \"verbosity\": -1,\n",
        "            \"seed\": SEED,\n",
        "            # ★ ここが重要：quantile では単調性制約を外す\n",
        "            # \"monotone_constraints\": monotone_constraints,  # ←入れない\n",
        "        })\n",
        "        models_q[tag] = lgb.train(q_params, dtrain, num_boost_round=best_round)\n",
        "\n",
        "    return model_point, models_q\n"
      ],
      "metadata": {
        "id": "y2CDOFoaBSBj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 入力CSV→中間CSVの自動生成（なければ作る） =====\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np, re\n",
        "from datetime import datetime\n",
        "\n",
        "RAW_CSV = Path(\"Tokyo_Chuo Ward_20242_20251.csv\")\n",
        "IN = Path(\"data/interim/train_tabular.csv\")\n",
        "ST_OUT = Path(\"data/interim/stations.csv\")\n",
        "IN.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _read_chuo_and_save(raw_csv: Path, out_csv: Path, stations_csv: Path):\n",
        "    # エンコーディングを順に試す（Excel想定）\n",
        "    last_err = None\n",
        "    for enc in (\"cp932\", \"utf-8-sig\", \"utf-8\", \"utf-16\", \"utf-16le\", \"utf-16be\"):\n",
        "        try:\n",
        "            raw = pd.read_csv(raw_csv, encoding=enc)\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            raw = None\n",
        "    if raw is None:\n",
        "        raise last_err\n",
        "\n",
        "    def _to_year(x):\n",
        "        if pd.isna(x): return np.nan\n",
        "        m = re.search(r\"(\\d{4})年\", str(x))\n",
        "        return int(m.group(1)) if m else np.nan\n",
        "\n",
        "    df = raw[[\"最寄駅：名称\",\"最寄駅：距離（分）\",\"間取り\",\"面積（㎡）\",\"建築年\",\"取引価格（総額）\"]].copy()\n",
        "\n",
        "    build_year = df[\"建築年\"].apply(_to_year)\n",
        "    current_year = datetime.now().year\n",
        "    df[\"築年数\"] = (current_year - build_year).clip(lower=0)\n",
        "\n",
        "    for col in [\"最寄駅：距離（分）\",\"面積（㎡）\",\"築年数\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(df[col].median())\n",
        "\n",
        "    def _normalize_layout(s):\n",
        "        if not isinstance(s,str): return \"その他\"\n",
        "        s = s.upper().replace(\"Ｌ\",\"L\").replace(\"Ｄ\",\"D\").replace(\"Ｋ\",\"K\").replace(\"Ｒ\",\"R\")\n",
        "        m = re.search(r\"(\\d+)(LDK|DK|K|R)\", s)\n",
        "        return m.group(0) if m else \"その他\"\n",
        "\n",
        "    train = df.rename(columns={\n",
        "        \"最寄駅：名称\":\"station\",\n",
        "        \"最寄駅：距離（分）\":\"walk_min\",\n",
        "        \"面積（㎡）\":\"area_sqm\",\n",
        "        \"取引価格（総額）\":\"price_yen\",\n",
        "    })[[\"station\",\"walk_min\",\"築年数\",\"area_sqm\",\"price_yen\"]].copy()\n",
        "    train[\"layout\"] = df[\"間取り\"].astype(str).apply(_normalize_layout)\n",
        "\n",
        "    # 保存（StreamlitもこのCSVを読む）\n",
        "    train.to_csv(out_csv, index=False)\n",
        "\n",
        "    # 駅リスト保存（utf-8-sig）\n",
        "    s = (raw[\"最寄駅：名称\"].astype(str)\n",
        "           .replace({\"nan\":np.nan,\"None\":np.nan,\"\":np.nan})\n",
        "           .dropna()\n",
        "           .str.normalize(\"NFKC\")\n",
        "           .str.replace(\"（\",\"(\",regex=False).str.replace(\"）\",\")\",regex=False)\n",
        "           .str.replace(\"　\",\" \",regex=False).str.strip()\n",
        "           .str.replace(r\"\\s+\",\" \",regex=True))\n",
        "    pd.Series(sorted(s.unique())).to_csv(stations_csv, index=False, header=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# まだ中間CSVがない場合は作る\n",
        "if not IN.exists():\n",
        "    if not RAW_CSV.exists():\n",
        "        raise FileNotFoundError(f\"Raw CSV が見つかりません: {RAW_CSV.resolve()}\")\n",
        "    _read_chuo_and_save(RAW_CSV, IN, ST_OUT)"
      ],
      "metadata": {
        "id": "djgwH5z8AQKF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1m-pW2KQAQGD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 4) 実行\n",
        "# ============================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    assert IN.exists(), f\"Not found: {IN}\"\n",
        "\n",
        "    # ★ infer_maps まで受け取る（関数が infer_maps を返す実装になっている前提）\n",
        "    X_df, y_log, cat_cols, mono_cons, meta, oe, infer_maps = build_table_and_features()\n",
        "\n",
        "    print(f\"Train rows: {len(X_df):,}, cols: {X_df.shape[1]} (cats={len(cat_cols)})\")\n",
        "\n",
        "    best_params, best_round, best_score = tune_with_optuna(\n",
        "        X_df, y_log, cat_cols, mono_cons, n_trials=80\n",
        "    )\n",
        "    print(\"[OPTUNA] best RMSLE:\", round(best_score, 4))\n",
        "    print(\"[OPTUNA] best params:\")\n",
        "    for k, v in best_params.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print(\"[OPTUNA] best_round:\", best_round)\n",
        "\n",
        "    model_point, models_q = train_final_models(\n",
        "        X_df, y_log, cat_cols, mono_cons, best_params, best_round\n",
        "    )\n",
        "\n",
        "    # ===== 保存 =====\n",
        "    # 予測時に使うメタ情報（列順や制約）とエンコーダを一緒に保存しておく\n",
        "    dump({\n",
        "        \"model\": model_point,\n",
        "        \"encoder\": oe,\n",
        "        \"cat_cols\": meta[\"feat_cat\"],\n",
        "        \"num_cols\": meta[\"feat_num\"],\n",
        "        \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "        \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "        \"target\": \"log_price_yen\",\n",
        "    }, OUT_DIR / \"lgbm_optuna_point.pkl\")\n",
        "\n",
        "    dump({\n",
        "        \"model\": models_q[\"q10\"],\n",
        "        \"encoder\": oe,\n",
        "        \"cat_cols\": meta[\"feat_cat\"],\n",
        "        \"num_cols\": meta[\"feat_num\"],\n",
        "        \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "        \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "        \"target\": \"log_price_yen\",\n",
        "        \"alpha\": 0.1,\n",
        "    }, OUT_DIR / \"lgbm_optuna_q10.pkl\")\n",
        "\n",
        "    dump({\n",
        "        \"model\": models_q[\"q90\"],\n",
        "        \"encoder\": oe,\n",
        "        \"cat_cols\": meta[\"feat_cat\"],\n",
        "        \"num_cols\": meta[\"feat_num\"],\n",
        "        \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "        \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "        \"target\": \"log_price_yen\",\n",
        "        \"alpha\": 0.9,\n",
        "    }, OUT_DIR / \"lgbm_optuna_q90.pkl\")\n",
        "\n",
        "    with open(OUT_DIR / \"feature_config.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\n",
        "            \"feat_cat\": meta[\"feat_cat\"],\n",
        "            \"feat_num\": meta[\"feat_num\"],\n",
        "            \"categorical_feature\": meta[\"categorical_feature\"],\n",
        "            \"monotone_constraints\": meta[\"monotone_constraints\"],\n",
        "            \"notes\": \"y is log1p(price_yen). During inference, apply expm1 to predictions.\",\n",
        "        }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # ★ 推論用マップも保存（カッコを閉じるのを忘れない）\n",
        "    with open(OUT_DIR / \"infer_maps.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(infer_maps, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(\"Saved models →\", OUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgDG4Y1nAbPv",
        "outputId": "6b485b96-213c-4372-feb4-9756690cc292"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 04:56:38,916] A new study created in memory with name: no-name-e5105b91-3a26-443f-bff8-944a575f7a2b\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 1,790, cols: 14 (cats=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-31 04:56:39,398] Trial 0 finished with value: 0.2223270006339794 and parameters: {'learning_rate': 0.0224870652682418, 'num_leaves': 82, 'min_data_in_leaf': 26, 'feature_fraction': 0.6956922071735372, 'bagging_fraction': 0.717103600847071, 'bagging_freq': 1, 'min_gain_to_split': 3.7931862717074494, 'lambda_l1': 1.4377493849465108e-07, 'lambda_l2': 0.07754491657556242}. Best is trial 0 with value: 0.2223270006339794.\n",
            "[I 2025-08-31 04:56:39,525] Trial 1 finished with value: 0.2339625365470332 and parameters: {'learning_rate': 0.08177481064792305, 'num_leaves': 189, 'min_data_in_leaf': 44, 'feature_fraction': 0.6925901060909725, 'bagging_fraction': 0.8275314978070927, 'bagging_freq': 5, 'min_gain_to_split': 4.654226073533716, 'lambda_l1': 7.500766770654669e-08, 'lambda_l2': 3.415734804086897e-07}. Best is trial 0 with value: 0.2223270006339794.\n",
            "[I 2025-08-31 04:56:39,668] Trial 2 finished with value: 0.21648147483334093 and parameters: {'learning_rate': 0.10272084463683699, 'num_leaves': 213, 'min_data_in_leaf': 139, 'feature_fraction': 0.7245786386387422, 'bagging_fraction': 0.7823526789631665, 'bagging_freq': 4, 'min_gain_to_split': 0.4784352187395591, 'lambda_l1': 0.00017181196745464007, 'lambda_l2': 1.2003595124725816e-05}. Best is trial 2 with value: 0.21648147483334093.\n",
            "[I 2025-08-31 04:56:39,901] Trial 3 finished with value: 0.28182242672432795 and parameters: {'learning_rate': 0.014012696463192314, 'num_leaves': 80, 'min_data_in_leaf': 199, 'feature_fraction': 0.7480478761045958, 'bagging_fraction': 0.6782165413722774, 'bagging_freq': 9, 'min_gain_to_split': 4.164960230718766, 'lambda_l1': 2.27972452417087, 'lambda_l2': 1.2065300945585876e-06}. Best is trial 2 with value: 0.21648147483334093.\n",
            "[I 2025-08-31 04:56:40,021] Trial 4 finished with value: 0.2067670799366666 and parameters: {'learning_rate': 0.15706234305298408, 'num_leaves': 205, 'min_data_in_leaf': 43, 'feature_fraction': 0.6784342271045938, 'bagging_fraction': 0.9916554787552025, 'bagging_freq': 5, 'min_gain_to_split': 1.80585209082109, 'lambda_l1': 2.71900205461635e-07, 'lambda_l2': 1.5425469715042242e-06}. Best is trial 4 with value: 0.2067670799366666.\n",
            "[I 2025-08-31 04:56:40,283] Trial 5 finished with value: 0.22370513524086832 and parameters: {'learning_rate': 0.027400016649977446, 'num_leaves': 173, 'min_data_in_leaf': 140, 'feature_fraction': 0.7859997901717883, 'bagging_fraction': 0.8851061646953, 'bagging_freq': 9, 'min_gain_to_split': 1.6669617570798179, 'lambda_l1': 0.0666119458783379, 'lambda_l2': 1.6000162998737838e-06}. Best is trial 4 with value: 0.2067670799366666.\n",
            "[I 2025-08-31 04:56:40,511] Trial 6 finished with value: 0.23086298164757507 and parameters: {'learning_rate': 0.01963783230524356, 'num_leaves': 57, 'min_data_in_leaf': 96, 'feature_fraction': 0.809237266732777, 'bagging_fraction': 0.6867631600041633, 'bagging_freq': 0, 'min_gain_to_split': 4.270947848895429, 'lambda_l1': 1.3590462531490172e-07, 'lambda_l2': 0.25440808919826896}. Best is trial 4 with value: 0.2067670799366666.\n",
            "[I 2025-08-31 04:56:40,744] Trial 7 finished with value: 0.23248334380107405 and parameters: {'learning_rate': 0.05623785118134065, 'num_leaves': 128, 'min_data_in_leaf': 108, 'feature_fraction': 0.6264118467088985, 'bagging_fraction': 0.9415196523410585, 'bagging_freq': 1, 'min_gain_to_split': 4.889626010309806, 'lambda_l1': 1.7466262676922672e-05, 'lambda_l2': 2.549969398450165e-07}. Best is trial 4 with value: 0.2067670799366666.\n",
            "[I 2025-08-31 04:56:41,097] Trial 8 finished with value: 0.22566234517168562 and parameters: {'learning_rate': 0.012482062737432157, 'num_leaves': 194, 'min_data_in_leaf': 113, 'feature_fraction': 0.7962573758654146, 'bagging_fraction': 0.9841868117631115, 'bagging_freq': 6, 'min_gain_to_split': 3.0613078307808945, 'lambda_l1': 1.1688688745243595e-08, 'lambda_l2': 0.0007409782822329734}. Best is trial 4 with value: 0.2067670799366666.\n",
            "[I 2025-08-31 04:56:41,437] Trial 9 finished with value: 0.20875358643323905 and parameters: {'learning_rate': 0.02414860660074466, 'num_leaves': 136, 'min_data_in_leaf': 83, 'feature_fraction': 0.8198944210158986, 'bagging_fraction': 0.6053813087849573, 'bagging_freq': 2, 'min_gain_to_split': 0.6177926935027395, 'lambda_l1': 1.6800009925359703e-05, 'lambda_l2': 1.4595334713749078e-05}. Best is trial 4 with value: 0.2067670799366666.\n",
            "[I 2025-08-31 04:56:41,591] Trial 10 finished with value: 0.20693022149053414 and parameters: {'learning_rate': 0.19942009178584807, 'num_leaves': 229, 'min_data_in_leaf': 11, 'feature_fraction': 0.9633483430395442, 'bagging_fraction': 0.9038433329459958, 'bagging_freq': 7, 'min_gain_to_split': 1.8643919545519505, 'lambda_l1': 0.008631985123019928, 'lambda_l2': 1.1116434289796351e-08}. Best is trial 4 with value: 0.2067670799366666.\n",
            "[I 2025-08-31 04:56:41,749] Trial 11 finished with value: 0.20579382774223443 and parameters: {'learning_rate': 0.1998183341204106, 'num_leaves': 241, 'min_data_in_leaf': 15, 'feature_fraction': 0.9646319130408422, 'bagging_fraction': 0.9985469341740959, 'bagging_freq': 7, 'min_gain_to_split': 1.8482466743214359, 'lambda_l1': 0.017174430254714143, 'lambda_l2': 1.2497762631798093e-08}. Best is trial 11 with value: 0.20579382774223443.\n",
            "[I 2025-08-31 04:56:41,908] Trial 12 finished with value: 0.20776055589927583 and parameters: {'learning_rate': 0.18976096601920647, 'num_leaves': 250, 'min_data_in_leaf': 55, 'feature_fraction': 0.9929261197424304, 'bagging_fraction': 0.9814371009901576, 'bagging_freq': 7, 'min_gain_to_split': 1.8063508109554292, 'lambda_l1': 0.004981806267310187, 'lambda_l2': 2.0310642624501342e-08}. Best is trial 11 with value: 0.20579382774223443.\n",
            "[I 2025-08-31 04:56:42,070] Trial 13 finished with value: 0.23089013245515283 and parameters: {'learning_rate': 0.11577550172749118, 'num_leaves': 254, 'min_data_in_leaf': 61, 'feature_fraction': 0.8816024918010079, 'bagging_fraction': 0.9931984329683357, 'bagging_freq': 4, 'min_gain_to_split': 2.6777054292098335, 'lambda_l1': 7.391967209453587, 'lambda_l2': 0.0005996692214100573}. Best is trial 11 with value: 0.20579382774223443.\n",
            "[I 2025-08-31 04:56:42,231] Trial 14 finished with value: 0.20419595112017513 and parameters: {'learning_rate': 0.1457878647554833, 'num_leaves': 163, 'min_data_in_leaf': 14, 'feature_fraction': 0.9109648845276137, 'bagging_fraction': 0.8531569695982699, 'bagging_freq': 10, 'min_gain_to_split': 1.17660231688836, 'lambda_l1': 4.44030795905758e-06, 'lambda_l2': 7.540227407754165}. Best is trial 14 with value: 0.20419595112017513.\n",
            "[I 2025-08-31 04:56:42,460] Trial 15 finished with value: 0.20135660182209522 and parameters: {'learning_rate': 0.054059775113359854, 'num_leaves': 167, 'min_data_in_leaf': 12, 'feature_fraction': 0.9162319702563267, 'bagging_fraction': 0.8328064946238459, 'bagging_freq': 10, 'min_gain_to_split': 0.9610523970286557, 'lambda_l1': 4.629906590217907e-06, 'lambda_l2': 6.022343109616454}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:42,683] Trial 16 finished with value: 0.20746568339431198 and parameters: {'learning_rate': 0.04852551058969218, 'num_leaves': 160, 'min_data_in_leaf': 75, 'feature_fraction': 0.8978708906493176, 'bagging_fraction': 0.8257326623804251, 'bagging_freq': 10, 'min_gain_to_split': 0.9912123777175821, 'lambda_l1': 5.397456414586662e-06, 'lambda_l2': 6.321620737284257}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:42,877] Trial 17 finished with value: 0.20504556431637902 and parameters: {'learning_rate': 0.06887885490413935, 'num_leaves': 107, 'min_data_in_leaf': 32, 'feature_fraction': 0.878684611163874, 'bagging_fraction': 0.7574971315418644, 'bagging_freq': 10, 'min_gain_to_split': 1.092800760257575, 'lambda_l1': 2.5899871811839224e-06, 'lambda_l2': 7.731592658212259}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:43,350] Trial 18 finished with value: 0.2026886773773692 and parameters: {'learning_rate': 0.038491870664735896, 'num_leaves': 160, 'min_data_in_leaf': 138, 'feature_fraction': 0.9210780688729664, 'bagging_fraction': 0.850400131330453, 'bagging_freq': 8, 'min_gain_to_split': 0.05494747235490438, 'lambda_l1': 0.0007222129373736292, 'lambda_l2': 0.04925951536286685}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:43,938] Trial 19 finished with value: 0.21183060107368717 and parameters: {'learning_rate': 0.035821267900109914, 'num_leaves': 112, 'min_data_in_leaf': 198, 'feature_fraction': 0.8484004035997005, 'bagging_fraction': 0.8982000288405141, 'bagging_freq': 8, 'min_gain_to_split': 0.030454554147944353, 'lambda_l1': 0.00039913217949237123, 'lambda_l2': 0.03601425781995375}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:44,223] Trial 20 finished with value: 0.2257873618735557 and parameters: {'learning_rate': 0.03633590133082424, 'num_leaves': 147, 'min_data_in_leaf': 168, 'feature_fraction': 0.9338670041618772, 'bagging_fraction': 0.7515551151422678, 'bagging_freq': 8, 'min_gain_to_split': 0.2571744451648258, 'lambda_l1': 0.00024843096920449656, 'lambda_l2': 0.009528429286626762}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:44,496] Trial 21 finished with value: 0.21915098801299715 and parameters: {'learning_rate': 0.03873497600132777, 'num_leaves': 179, 'min_data_in_leaf': 130, 'feature_fraction': 0.924744875473124, 'bagging_fraction': 0.85211132428804, 'bagging_freq': 10, 'min_gain_to_split': 1.1407830825125034, 'lambda_l1': 1.3752577123845137e-06, 'lambda_l2': 0.9690657270820079}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:44,695] Trial 22 finished with value: 0.22454598953295704 and parameters: {'learning_rate': 0.06584300471139527, 'num_leaves': 160, 'min_data_in_leaf': 165, 'feature_fraction': 0.9241546749634192, 'bagging_fraction': 0.8679185089574704, 'bagging_freq': 9, 'min_gain_to_split': 0.738407808401147, 'lambda_l1': 0.0005432444999064225, 'lambda_l2': 0.9718577870805001}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:44,861] Trial 23 finished with value: 0.23150854068270332 and parameters: {'learning_rate': 0.11105923928139051, 'num_leaves': 159, 'min_data_in_leaf': 161, 'feature_fraction': 0.8555637522012027, 'bagging_fraction': 0.8017499269912235, 'bagging_freq': 8, 'min_gain_to_split': 1.3355624405088027, 'lambda_l1': 3.853346332998127e-05, 'lambda_l2': 0.00876646993874358}. Best is trial 15 with value: 0.20135660182209522.\n",
            "[I 2025-08-31 04:56:45,988] Trial 24 finished with value: 0.18095693112921957 and parameters: {'learning_rate': 0.01642120394700686, 'num_leaves': 118, 'min_data_in_leaf': 31, 'feature_fraction': 0.9968166765600607, 'bagging_fraction': 0.936813614648039, 'bagging_freq': 10, 'min_gain_to_split': 0.03314418345064859, 'lambda_l1': 9.646432958455583e-07, 'lambda_l2': 0.8896184245388651}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:56:51,123] Trial 25 finished with value: 0.18760724475958143 and parameters: {'learning_rate': 0.01559853826510379, 'num_leaves': 104, 'min_data_in_leaf': 125, 'feature_fraction': 0.9824186566489762, 'bagging_fraction': 0.9482957073587838, 'bagging_freq': 9, 'min_gain_to_split': 0.0021833748481920046, 'lambda_l1': 5.145538222885123e-07, 'lambda_l2': 0.7301845867185771}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:56:51,715] Trial 26 finished with value: 0.1998981771447708 and parameters: {'learning_rate': 0.013818218030485658, 'num_leaves': 100, 'min_data_in_leaf': 71, 'feature_fraction': 0.9896944765090051, 'bagging_fraction': 0.9393919846756695, 'bagging_freq': 9, 'min_gain_to_split': 0.4860223327707372, 'lambda_l1': 7.659379708250998e-07, 'lambda_l2': 0.8288536786489593}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:56:52,219] Trial 27 finished with value: 0.2015348699009666 and parameters: {'learning_rate': 0.015046818646437072, 'num_leaves': 91, 'min_data_in_leaf': 79, 'feature_fraction': 0.9957601677698935, 'bagging_fraction': 0.9381454754582896, 'bagging_freq': 9, 'min_gain_to_split': 0.5025136007180311, 'lambda_l1': 1.4111091870325525e-08, 'lambda_l2': 0.7833108197597776}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:56:52,981] Trial 28 finished with value: 0.20090916849149995 and parameters: {'learning_rate': 0.010051853029719433, 'num_leaves': 35, 'min_data_in_leaf': 94, 'feature_fraction': 0.9575590327631546, 'bagging_fraction': 0.9497455709345919, 'bagging_freq': 6, 'min_gain_to_split': 0.3263617338491656, 'lambda_l1': 7.242815744656996e-07, 'lambda_l2': 0.004189830965443627}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:56:53,336] Trial 29 finished with value: 0.21469341700592853 and parameters: {'learning_rate': 0.018058919382622694, 'num_leaves': 80, 'min_data_in_leaf': 62, 'feature_fraction': 0.9965105742502902, 'bagging_fraction': 0.9189734007111515, 'bagging_freq': 9, 'min_gain_to_split': 2.2996007282407724, 'lambda_l1': 5.586964532986547e-08, 'lambda_l2': 0.4865237236157639}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:56:58,507] Trial 30 finished with value: 0.18726024942912906 and parameters: {'learning_rate': 0.010105699941300447, 'num_leaves': 109, 'min_data_in_leaf': 118, 'feature_fraction': 0.9560856839843735, 'bagging_fraction': 0.9594919523761412, 'bagging_freq': 3, 'min_gain_to_split': 0.00023493171542855046, 'lambda_l1': 3.980374157027012e-07, 'lambda_l2': 0.14630102780146248}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:00,797] Trial 31 finished with value: 0.20338332025059375 and parameters: {'learning_rate': 0.010495833489014773, 'num_leaves': 118, 'min_data_in_leaf': 125, 'feature_fraction': 0.964884934031607, 'bagging_fraction': 0.9622586339075022, 'bagging_freq': 3, 'min_gain_to_split': 0.15884608407943163, 'lambda_l1': 4.7206640255471165e-07, 'lambda_l2': 0.1630466976151932}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:01,828] Trial 32 finished with value: 0.20772913180987337 and parameters: {'learning_rate': 0.01704463393438295, 'num_leaves': 97, 'min_data_in_leaf': 116, 'feature_fraction': 0.9461907471338923, 'bagging_fraction': 0.9234960390643407, 'bagging_freq': 1, 'min_gain_to_split': 0.7172555874674795, 'lambda_l1': 1.1170597252855176e-07, 'lambda_l2': 0.08498451159407122}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:02,255] Trial 33 finished with value: 0.2254649010891873 and parameters: {'learning_rate': 0.012577613361818464, 'num_leaves': 68, 'min_data_in_leaf': 95, 'feature_fraction': 0.9772044085457803, 'bagging_fraction': 0.9616417203271583, 'bagging_freq': 3, 'min_gain_to_split': 3.32994472067907, 'lambda_l1': 3.163784627837501e-08, 'lambda_l2': 2.0837607888939473}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:02,723] Trial 34 finished with value: 0.1932729518434944 and parameters: {'learning_rate': 0.021960725815125356, 'num_leaves': 122, 'min_data_in_leaf': 33, 'feature_fraction': 0.9797815742448837, 'bagging_fraction': 0.8848189870710651, 'bagging_freq': 4, 'min_gain_to_split': 0.4063650158143355, 'lambda_l1': 6.491544145017413e-07, 'lambda_l2': 0.022990706475355446}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:03,371] Trial 35 finished with value: 0.18416543292743387 and parameters: {'learning_rate': 0.026968132485489626, 'num_leaves': 125, 'min_data_in_leaf': 31, 'feature_fraction': 0.9424475778693021, 'bagging_fraction': 0.8889441440685689, 'bagging_freq': 4, 'min_gain_to_split': 0.06367870656437447, 'lambda_l1': 3.1828822048568106e-05, 'lambda_l2': 0.028382713203214803}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:03,910] Trial 36 finished with value: 0.18502719365344808 and parameters: {'learning_rate': 0.029878220326019472, 'num_leaves': 137, 'min_data_in_leaf': 41, 'feature_fraction': 0.9452170919410088, 'bagging_fraction': 0.9162354362382455, 'bagging_freq': 3, 'min_gain_to_split': 0.0694948376853115, 'lambda_l1': 5.8864096403409314e-05, 'lambda_l2': 0.16105046392572878}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:04,282] Trial 37 finished with value: 0.19903696766273588 and parameters: {'learning_rate': 0.02870852044722829, 'num_leaves': 139, 'min_data_in_leaf': 42, 'feature_fraction': 0.7537127891880989, 'bagging_fraction': 0.9155766452860711, 'bagging_freq': 3, 'min_gain_to_split': 0.8172878325452131, 'lambda_l1': 4.953252315606342e-05, 'lambda_l2': 0.003915394928583438}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:04,597] Trial 38 finished with value: 0.20415634312583256 and parameters: {'learning_rate': 0.02972437215531046, 'num_leaves': 145, 'min_data_in_leaf': 25, 'feature_fraction': 0.9424939667852487, 'bagging_fraction': 0.8722873689448152, 'bagging_freq': 2, 'min_gain_to_split': 1.3726028683005544, 'lambda_l1': 4.5240746426143666e-05, 'lambda_l2': 0.1285101960122119}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:05,053] Trial 39 finished with value: 0.19399658258424574 and parameters: {'learning_rate': 0.02082586391079244, 'num_leaves': 60, 'min_data_in_leaf': 51, 'feature_fraction': 0.8893570768756567, 'bagging_fraction': 0.9721087101326569, 'bagging_freq': 4, 'min_gain_to_split': 0.3852344321384027, 'lambda_l1': 0.00012009063234069684, 'lambda_l2': 0.25756598743413117}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:05,951] Trial 40 finished with value: 0.18865561405828402 and parameters: {'learning_rate': 0.01171183033248952, 'num_leaves': 124, 'min_data_in_leaf': 25, 'feature_fraction': 0.8467033076604017, 'bagging_fraction': 0.894276037943025, 'bagging_freq': 5, 'min_gain_to_split': 0.2588185460089272, 'lambda_l1': 0.001455592831223748, 'lambda_l2': 0.0020033325454780577}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:07,309] Trial 41 finished with value: 0.19927055827913515 and parameters: {'learning_rate': 0.015901786550731364, 'num_leaves': 83, 'min_data_in_leaf': 152, 'feature_fraction': 0.9468739997504289, 'bagging_fraction': 0.9292316195452759, 'bagging_freq': 2, 'min_gain_to_split': 0.027838607355394687, 'lambda_l1': 2.1733496971612173e-07, 'lambda_l2': 6.879876108553287e-05}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:09,551] Trial 42 finished with value: 0.18832085004786134 and parameters: {'learning_rate': 0.024412651017781038, 'num_leaves': 133, 'min_data_in_leaf': 124, 'feature_fraction': 0.9719909952471224, 'bagging_fraction': 0.9565336700822455, 'bagging_freq': 5, 'min_gain_to_split': 0.005309493349692759, 'lambda_l1': 8.3573383842558e-06, 'lambda_l2': 1.9722919834628267}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:10,042] Trial 43 finished with value: 0.19659097292594682 and parameters: {'learning_rate': 0.01845863113520372, 'num_leaves': 109, 'min_data_in_leaf': 47, 'feature_fraction': 0.9440835701348412, 'bagging_fraction': 0.9029000589538321, 'bagging_freq': 3, 'min_gain_to_split': 0.6191264073822546, 'lambda_l1': 1.2636592848007613e-05, 'lambda_l2': 0.019282075270171724}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:10,279] Trial 44 finished with value: 0.2323929394780952 and parameters: {'learning_rate': 0.025748115236397598, 'num_leaves': 147, 'min_data_in_leaf': 33, 'feature_fraction': 0.9031233376338367, 'bagging_fraction': 0.6262197787747379, 'bagging_freq': 4, 'min_gain_to_split': 3.7443805624556417, 'lambda_l1': 2.8881323026543336e-07, 'lambda_l2': 0.35084562096798944}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:10,900] Trial 45 finished with value: 0.20045298983139492 and parameters: {'learning_rate': 0.013801860843849444, 'num_leaves': 90, 'min_data_in_leaf': 104, 'feature_fraction': 0.6020834569762227, 'bagging_fraction': 0.9744644605764866, 'bagging_freq': 2, 'min_gain_to_split': 0.2707399759356557, 'lambda_l1': 0.00010061243019956495, 'lambda_l2': 2.5886368685719416}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:11,175] Trial 46 finished with value: 0.21419339567738532 and parameters: {'learning_rate': 0.03167923363432152, 'num_leaves': 129, 'min_data_in_leaf': 148, 'feature_fraction': 0.7147756388047928, 'bagging_fraction': 0.947639598776818, 'bagging_freq': 0, 'min_gain_to_split': 0.8414369643964377, 'lambda_l1': 1.8216167009589015e-06, 'lambda_l2': 0.047501839248104485}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:11,607] Trial 47 finished with value: 0.2157629774211432 and parameters: {'learning_rate': 0.020677041824502425, 'num_leaves': 118, 'min_data_in_leaf': 66, 'feature_fraction': 0.956783492726856, 'bagging_fraction': 0.9218825978670739, 'bagging_freq': 6, 'min_gain_to_split': 2.2247658567821493, 'lambda_l1': 2.820695878224547e-05, 'lambda_l2': 0.0002125949116927223}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:13,554] Trial 48 finished with value: 0.20115502051630213 and parameters: {'learning_rate': 0.01198877911352561, 'num_leaves': 101, 'min_data_in_leaf': 86, 'feature_fraction': 0.6561937254439665, 'bagging_fraction': 0.9991153926097817, 'bagging_freq': 1, 'min_gain_to_split': 0.5539412366335538, 'lambda_l1': 4.7955858327971366e-08, 'lambda_l2': 0.11648098794931691}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:14,130] Trial 49 finished with value: 0.20728494030705655 and parameters: {'learning_rate': 0.01586140599416608, 'num_leaves': 182, 'min_data_in_leaf': 39, 'feature_fraction': 0.9768408673930554, 'bagging_fraction': 0.8750201858219371, 'bagging_freq': 4, 'min_gain_to_split': 1.5159424466435032, 'lambda_l1': 0.20623659473262362, 'lambda_l2': 2.4492025683558687}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:14,335] Trial 50 finished with value: 0.2290164758125673 and parameters: {'learning_rate': 0.043674868582816904, 'num_leaves': 74, 'min_data_in_leaf': 20, 'feature_fraction': 0.8699515996545057, 'bagging_fraction': 0.9087441556990735, 'bagging_freq': 5, 'min_gain_to_split': 4.50088089080727, 'lambda_l1': 3.096693905218968e-06, 'lambda_l2': 0.27832696892838155}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:14,957] Trial 51 finished with value: 0.1981167553559725 and parameters: {'learning_rate': 0.02404478553924052, 'num_leaves': 134, 'min_data_in_leaf': 116, 'feature_fraction': 0.97222901360602, 'bagging_fraction': 0.9598918788573136, 'bagging_freq': 5, 'min_gain_to_split': 0.055267887122971086, 'lambda_l1': 8.94758990147557e-06, 'lambda_l2': 2.1575228713760506}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:15,384] Trial 52 finished with value: 0.20423691852118062 and parameters: {'learning_rate': 0.023316027603147018, 'num_leaves': 133, 'min_data_in_leaf': 125, 'feature_fraction': 0.9862344779018042, 'bagging_fraction': 0.978144671690108, 'bagging_freq': 3, 'min_gain_to_split': 0.2014327333157087, 'lambda_l1': 9.299906762812423e-06, 'lambda_l2': 3.437642950938278}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:16,224] Trial 53 finished with value: 0.18960689381277848 and parameters: {'learning_rate': 0.03293783114073395, 'num_leaves': 111, 'min_data_in_leaf': 108, 'feature_fraction': 0.9982759532131416, 'bagging_fraction': 0.951522041288164, 'bagging_freq': 6, 'min_gain_to_split': 0.014958054423645551, 'lambda_l1': 1.8315312941937084e-06, 'lambda_l2': 0.42594392077618864}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:16,620] Trial 54 finished with value: 0.20849925211690215 and parameters: {'learning_rate': 0.026647283798058516, 'num_leaves': 148, 'min_data_in_leaf': 135, 'feature_fraction': 0.9591741546014259, 'bagging_fraction': 0.9392126017230455, 'bagging_freq': 5, 'min_gain_to_split': 0.4432867264541166, 'lambda_l1': 1.432267015123016e-07, 'lambda_l2': 1.2955677785201885}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:17,124] Trial 55 finished with value: 0.20463932707810645 and parameters: {'learning_rate': 0.01851568275139931, 'num_leaves': 116, 'min_data_in_leaf': 123, 'feature_fraction': 0.9386304511703691, 'bagging_fraction': 0.9304873611480111, 'bagging_freq': 4, 'min_gain_to_split': 0.21527206818416908, 'lambda_l1': 1.8618825714152604e-05, 'lambda_l2': 0.05737336334830543}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:17,713] Trial 56 finished with value: 0.2129226934668847 and parameters: {'learning_rate': 0.011134914115352357, 'num_leaves': 129, 'min_data_in_leaf': 142, 'feature_fraction': 0.9266123628611608, 'bagging_fraction': 0.9840576787599657, 'bagging_freq': 3, 'min_gain_to_split': 0.8791689247157104, 'lambda_l1': 7.913187274691704e-05, 'lambda_l2': 0.01203887196808591}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:18,231] Trial 57 finished with value: 0.2090305052924558 and parameters: {'learning_rate': 0.01345502349271413, 'num_leaves': 205, 'min_data_in_leaf': 113, 'feature_fraction': 0.9081615634554792, 'bagging_fraction': 0.8890909979941799, 'bagging_freq': 7, 'min_gain_to_split': 0.64131687995489, 'lambda_l1': 0.001300100845482022, 'lambda_l2': 9.999379737721835}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:19,258] Trial 58 finished with value: 0.18433946079373273 and parameters: {'learning_rate': 0.04314634823724201, 'num_leaves': 151, 'min_data_in_leaf': 103, 'feature_fraction': 0.8298315347137255, 'bagging_fraction': 0.966706683208147, 'bagging_freq': 5, 'min_gain_to_split': 0.007069502210225381, 'lambda_l1': 6.914755749914765e-06, 'lambda_l2': 0.1361576489218736}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:19,502] Trial 59 finished with value: 0.22475873861161713 and parameters: {'learning_rate': 0.04568737177523494, 'num_leaves': 173, 'min_data_in_leaf': 176, 'feature_fraction': 0.8241351292494495, 'bagging_fraction': 0.8200711633115985, 'bagging_freq': 10, 'min_gain_to_split': 0.3879993378286051, 'lambda_l1': 1.2370452415289681e-06, 'lambda_l2': 0.1521906945269606}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:19,817] Trial 60 finished with value: 0.19188200312740522 and parameters: {'learning_rate': 0.05754590111152189, 'num_leaves': 100, 'min_data_in_leaf': 59, 'feature_fraction': 0.8908573886960799, 'bagging_fraction': 0.9088792004026988, 'bagging_freq': 2, 'min_gain_to_split': 0.20461965046042382, 'lambda_l1': 3.7721603145080575e-07, 'lambda_l2': 3.878130755832699e-07}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:20,434] Trial 61 finished with value: 0.18525980486317759 and parameters: {'learning_rate': 0.08910898609351878, 'num_leaves': 155, 'min_data_in_leaf': 105, 'feature_fraction': 0.778824768092465, 'bagging_fraction': 0.9655636670825068, 'bagging_freq': 5, 'min_gain_to_split': 0.005961019840689398, 'lambda_l1': 4.579905316022545e-06, 'lambda_l2': 0.615074678515202}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:20,674] Trial 62 finished with value: 0.1886708407825818 and parameters: {'learning_rate': 0.08640386266559885, 'num_leaves': 153, 'min_data_in_leaf': 37, 'feature_fraction': 0.7530308120411524, 'bagging_fraction': 0.968048993272398, 'bagging_freq': 6, 'min_gain_to_split': 0.17158878972794253, 'lambda_l1': 4.463939625856388e-06, 'lambda_l2': 0.5008436041124087}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:20,949] Trial 63 finished with value: 0.20356696525365595 and parameters: {'learning_rate': 0.040358433823751066, 'num_leaves': 139, 'min_data_in_leaf': 102, 'feature_fraction': 0.7762506654280951, 'bagging_fraction': 0.984325406604284, 'bagging_freq': 4, 'min_gain_to_split': 0.5171792221024625, 'lambda_l1': 2.2411568032410333e-05, 'lambda_l2': 0.03678854857319423}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:22,499] Trial 64 finished with value: 0.18116943480054495 and parameters: {'learning_rate': 0.05278622676267766, 'num_leaves': 153, 'min_data_in_leaf': 99, 'feature_fraction': 0.7324171747297907, 'bagging_fraction': 0.9377499006442684, 'bagging_freq': 5, 'min_gain_to_split': 0.0002943243616157047, 'lambda_l1': 1.2616182860758327e-06, 'lambda_l2': 0.08205619758943866}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:22,719] Trial 65 finished with value: 0.20115275150469453 and parameters: {'learning_rate': 0.0823407423001332, 'num_leaves': 152, 'min_data_in_leaf': 90, 'feature_fraction': 0.7258901374414535, 'bagging_fraction': 0.9338454440507427, 'bagging_freq': 5, 'min_gain_to_split': 0.34969757151955205, 'lambda_l1': 0.0001839781550642653, 'lambda_l2': 0.08075093363547271}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:22,901] Trial 66 finished with value: 0.21357488103534267 and parameters: {'learning_rate': 0.09425304822553013, 'num_leaves': 184, 'min_data_in_leaf': 102, 'feature_fraction': 0.7732405001283428, 'bagging_fraction': 0.6959518410467082, 'bagging_freq': 6, 'min_gain_to_split': 0.7025660303814548, 'lambda_l1': 1.0099364964952946e-06, 'lambda_l2': 0.020003458561282297}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:23,069] Trial 67 finished with value: 0.20933072937912184 and parameters: {'learning_rate': 0.13633057180252742, 'num_leaves': 168, 'min_data_in_leaf': 76, 'feature_fraction': 0.7990066365516856, 'bagging_fraction': 0.7772590548443989, 'bagging_freq': 3, 'min_gain_to_split': 0.9744526147187085, 'lambda_l1': 5.745874759684231e-06, 'lambda_l2': 0.17717870407116065}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:23,416] Trial 68 finished with value: 0.18513670889794526 and parameters: {'learning_rate': 0.05227243431034672, 'num_leaves': 194, 'min_data_in_leaf': 19, 'feature_fraction': 0.732414312498829, 'bagging_fraction': 0.9910945180770603, 'bagging_freq': 4, 'min_gain_to_split': 0.15316903317343, 'lambda_l1': 2.7165492627905303e-06, 'lambda_l2': 0.004977096854746248}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:23,616] Trial 69 finished with value: 0.21485049736194406 and parameters: {'learning_rate': 0.07002115440180105, 'num_leaves': 155, 'min_data_in_leaf': 18, 'feature_fraction': 0.7369814183498419, 'bagging_fraction': 0.9911932993693069, 'bagging_freq': 4, 'min_gain_to_split': 2.8332220153288747, 'lambda_l1': 3.2770209352900325e-06, 'lambda_l2': 0.005618865005826709}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:23,957] Trial 70 finished with value: 0.1868999305471298 and parameters: {'learning_rate': 0.06352725273347809, 'num_leaves': 223, 'min_data_in_leaf': 26, 'feature_fraction': 0.6907263124585781, 'bagging_fraction': 0.9997411919378228, 'bagging_freq': 5, 'min_gain_to_split': 0.16499640050030387, 'lambda_l1': 5.986058737972066e-05, 'lambda_l2': 0.0017244498891392053}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:25,565] Trial 71 finished with value: 0.18368572024663088 and parameters: {'learning_rate': 0.05279171510378887, 'num_leaves': 212, 'min_data_in_leaf': 11, 'feature_fraction': 0.6862697429482869, 'bagging_fraction': 0.9731802104475723, 'bagging_freq': 5, 'min_gain_to_split': 0.13976082363555925, 'lambda_l1': 6.393028068502704e-05, 'lambda_l2': 0.0017294574755075055}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:26,178] Trial 72 finished with value: 0.18901033931499428 and parameters: {'learning_rate': 0.04856014114231937, 'num_leaves': 199, 'min_data_in_leaf': 14, 'feature_fraction': 0.6786425303368403, 'bagging_fraction': 0.9702706954436762, 'bagging_freq': 4, 'min_gain_to_split': 0.31899792268037874, 'lambda_l1': 0.0002869419602706608, 'lambda_l2': 0.000754240510226207}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:26,454] Trial 73 finished with value: 0.19205013606446636 and parameters: {'learning_rate': 0.052624485535627596, 'num_leaves': 223, 'min_data_in_leaf': 10, 'feature_fraction': 0.6486577864686796, 'bagging_fraction': 0.9487080709669337, 'bagging_freq': 5, 'min_gain_to_split': 0.5140093534152249, 'lambda_l1': 1.5135943490838133e-05, 'lambda_l2': 0.0018890233295097475}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:26,773] Trial 74 finished with value: 0.18559015859794145 and parameters: {'learning_rate': 0.061631948477331396, 'num_leaves': 212, 'min_data_in_leaf': 24, 'feature_fraction': 0.8267465151063905, 'bagging_fraction': 0.9859740624656756, 'bagging_freq': 5, 'min_gain_to_split': 0.13537555682419852, 'lambda_l1': 2.863268863845354e-05, 'lambda_l2': 0.014770520234077851}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:27,077] Trial 75 finished with value: 0.1933481223244317 and parameters: {'learning_rate': 0.07432546171835877, 'num_leaves': 191, 'min_data_in_leaf': 49, 'feature_fraction': 0.7647963801030556, 'bagging_fraction': 0.9409874984860119, 'bagging_freq': 6, 'min_gain_to_split': 0.3051587145194257, 'lambda_l1': 2.4326486341038626e-06, 'lambda_l2': 0.028425286897187263}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:27,288] Trial 76 finished with value: 0.23301079805088748 and parameters: {'learning_rate': 0.04292043624586598, 'num_leaves': 174, 'min_data_in_leaf': 30, 'feature_fraction': 0.6973935366178212, 'bagging_fraction': 0.9127090194373239, 'bagging_freq': 4, 'min_gain_to_split': 4.965303325247161, 'lambda_l1': 7.044173074440147e-06, 'lambda_l2': 0.00708209115835167}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:27,777] Trial 77 finished with value: 0.18436206651357423 and parameters: {'learning_rate': 0.035088003344757146, 'num_leaves': 238, 'min_data_in_leaf': 16, 'feature_fraction': 0.7145811429219494, 'bagging_fraction': 0.9694230324329334, 'bagging_freq': 7, 'min_gain_to_split': 0.13261680761782907, 'lambda_l1': 0.00014389955919501837, 'lambda_l2': 0.00020443515449362163}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:28,138] Trial 78 finished with value: 0.1941604306664506 and parameters: {'learning_rate': 0.034420379845163405, 'num_leaves': 239, 'min_data_in_leaf': 19, 'feature_fraction': 0.7106854908832818, 'bagging_fraction': 0.9256039591980662, 'bagging_freq': 8, 'min_gain_to_split': 0.6482246719003637, 'lambda_l1': 0.0009646153184669972, 'lambda_l2': 4.640125168586371e-05}. Best is trial 24 with value: 0.18095693112921957.\n",
            "[I 2025-08-31 04:57:28,368] Trial 79 finished with value: 0.21023821771933138 and parameters: {'learning_rate': 0.05054182697962271, 'num_leaves': 229, 'min_data_in_leaf': 43, 'feature_fraction': 0.7376781314384384, 'bagging_fraction': 0.9725137948764411, 'bagging_freq': 7, 'min_gain_to_split': 2.0271448403758168, 'lambda_l1': 0.0024614006353139593, 'lambda_l2': 0.0001429860942930003}. Best is trial 24 with value: 0.18095693112921957.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OPTUNA] best RMSLE: 0.181\n",
            "[OPTUNA] best params:\n",
            "  learning_rate: 0.01642120394700686\n",
            "  num_leaves: 118\n",
            "  min_data_in_leaf: 31\n",
            "  feature_fraction: 0.9968166765600607\n",
            "  bagging_fraction: 0.936813614648039\n",
            "  bagging_freq: 10\n",
            "  min_gain_to_split: 0.03314418345064859\n",
            "  lambda_l1: 9.646432958455583e-07\n",
            "  lambda_l2: 0.8896184245388651\n",
            "[OPTUNA] best_round: 438\n",
            "Saved models → models\n"
          ]
        }
      ]
    }
  ]
}